{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8GSTh/lo6wNuqXpRkxVhe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anchayadav/AutoTS/blob/main/DataVision_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MJTWY7X9V6F"
      },
      "outputs": [],
      "source": [
        "!pip install magenta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Implemet the code Audio"
      ],
      "metadata": {
        "id": "eZxrgxLVSJRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DBvM1V3hW3kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Implement  focus on genre-based music  generation: no thematic analysis of input tex is required\n",
        "import magenta.music as mm\n",
        "from magenta.models.music_vae import TrainedModel\n",
        "from magenta.models.music_vae import configs\n",
        "\n",
        "def generate_genre_based_music(genre, output_path='generated_music.mid'):\n",
        "\n",
        "    model_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
        "    model = TrainedModel(model_config, batch_size=4, checkpoint_dir_or_path='cat-mel_2bar_big.tar')\n",
        "\n",
        "\n",
        "    genre_conditions = {\n",
        "        'pop': [1, 0, 0, 0],\n",
        "        'rock': [0, 1, 0, 0],\n",
        "        'jazz': [0, 0, 1, 0],\n",
        "        'classical': [0, 0, 0, 1],\n",
        "    }\n",
        "\n",
        "    condition = genre_conditions.get(genre, [0, 0, 0, 0])\n",
        "\n",
        "\n",
        "    generated_sequence = model.sample(n=1, length=128, condition=condition)\n",
        "\n",
        "    mm.sequence_proto_to_midi_file(generated_sequence[0], output_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    selected_genre = 'rock'\n",
        "    generate_genre_based_music(selected_genre)"
      ],
      "metadata": {
        "id": "bWBH-08u9pOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "####implement the music recommendation of the song\n",
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "\n",
        "data = [\n",
        "    ('user1', 'song1', 5),\n",
        "    ('user1', 'song2', 4),\n",
        "    ('user2', 'song1', 3),\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load the dataset\n",
        "dataset = Dataset.load_from_df(data, reader)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "trainset, testset = train_test_split(dataset, test_size=0.2)\n",
        "\n",
        "# Use the k-NN algorithm for collaborative filtering\n",
        "sim_options = {\n",
        "    'name': 'cosine',\n",
        "    'user_based': False  ,\n",
        "}\n",
        "\n",
        "model = KNNBasic(sim_options=sim_options)\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(trainset)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.test(testset)\n",
        "\n",
        "\n",
        "user_id = 'user1'\n",
        "song_id = 'song1'\n",
        "\n",
        "\n",
        "top_n = model.get_neighbors(model.trainset.to_inner_uid(user_id), k=5)\n",
        "\n",
        "print(f\"Top 5 song recommendations for {user_id}:\")\n",
        "for song_inner_id in top_n:\n",
        "    song_raw_id = model.trainset.to_raw_iid(song_inner_id)\n",
        "    print(f\"Song ID: {song_raw_id}\")\n",
        "\n",
        "\n",
        "predicted_rating = model.predict(user_id, song_id).est\n",
        "print(f\"Predicted rating for {user_id} and {song_id}: {predicted_rating}\")"
      ],
      "metadata": {
        "id": "XCdM5BUF-4rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 500 song generated\n",
        "\n",
        "import magenta.music as mm\n",
        "from magenta.models.music_vae import TrainedModel\n",
        "from magenta.models.music_vae import configs\n",
        "\n",
        "def fine_tune_musicvae(client_songs, output_dir='fine_tuned_model'):\n",
        "\n",
        "    model_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
        "    model = TrainedModel(model_config, batch_size=4, checkpoint_dir_or_path='cat-mel_2bar_big.tar')\n",
        "\n",
        "\n",
        "    note_sequences = [mm.midi_file_to_note_sequence(song_path) for song_path in client_songs]\n",
        "\n",
        "\n",
        "    model.train(note_sequences, output_dir)\n",
        "\n",
        "\n",
        "client_songs = ['song1.mid', 'song2.mid', ...]  s\n",
        "fine_tune_musicvae(client_songs)"
      ],
      "metadata": {
        "id": "8JT2ZxnXJTyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Implement download option  at up to 320kbps quality\n",
        "\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "\n",
        "sp = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id='your_client_id', client_secret='your_client_secret'))\n",
        "\n",
        "def download_track(track_id, quality='320k'):\n",
        "    track_info = sp.track(track_id)\n",
        "    track_name = track_info['name']\n",
        "    artist_name = track_info['artists'][0]['name']\n",
        "\n",
        "\n",
        "    available_tracks = sp.track_audio_features(track_id)\n",
        "    selected_track = None\n",
        "\n",
        "    for track in available_tracks:\n",
        "        if track['bitrate'] == quality:\n",
        "            selected_track = track\n",
        "            break\n",
        "\n",
        "    if selected_track:\n",
        "        audio_url = selected_track['preview_url']\n",
        "\n",
        "        print(f\"Downloading '{track_name}' by {artist_name} at {quality} quality: {audio_url}\")\n",
        "    else:\n",
        "        print(f\"No {quality} quality track available for '{track_name}' by {artist_name}\")\n",
        "\n",
        "track_id = 'your_track_id'\n",
        "download_track(track_id)\n"
      ],
      "metadata": {
        "id": "e787ItFnJdxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###IMPlement the Code Video Assignment Code"
      ],
      "metadata": {
        "id": "SOeZ901cVb_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Define the preferredd resolution for the generated video (up to 4k) and ensure a highly-quaity output\n",
        "\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def generate_high_quality_video(output_path, resolution=(1920, 1080), duration=10, fps=30):\n",
        "\n",
        "    num_frames = duration * fps\n",
        "    frames = [np.random.randint(0, 255, size=(resolution[1], resolution[0], 3), dtype=np.uint8) for _ in range(num_frames)]\n",
        "\n",
        "    writer = imageio.get_writer(output_path, fps=fps, quality=9)\n",
        "    for frame in frames:\n",
        "        writer.append_data(frame)\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "output_video_path = 'output_video.mp4'\n",
        "generate_high_quality_video(output_video_path, resolution=(3840, 2160), duration=10, fps=30)"
      ],
      "metadata": {
        "id": "R_AtV89BSKyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " ###Develop technique for achiving fluid motion and dynamic transition in generated video\n",
        "\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def generate_smooth_transition_video(output_path, resolution=(1920, 1080), duration=10, fps=30):\n",
        "    num_frames = duration * fps\n",
        "    frames = []\n",
        "\n",
        "    for t in range(num_frames):\n",
        "        frame = generate_frame(t, num_frames, resolution)\n",
        "        frames.append(frame)\n",
        "\n",
        "\n",
        "    writer = imageio.get_writer(output_path, fps=fps)\n",
        "    for frame in frames:\n",
        "        writer.append_data(frame)\n",
        "    writer.close()\n",
        "\n",
        "def generate_frame(t, num_frames, resolution):\n",
        "\n",
        "    color = hsv_to_rgb((t / num_frames, 1.0, 1.0))\n",
        "    frame = np.zeros((resolution[1], resolution[0], 3), dtype=np.uint8)\n",
        "    frame[:, :] = (color * 255).astype(np.uint8)\n",
        "    return frame\n",
        "\n",
        "def hsv_to_rgb(hsv):\n",
        "    h, s, v = hsv\n",
        "    if s == 0.0:\n",
        "        return v, v, v\n",
        "    i = int(h * 6.0)\n",
        "    f = (h * 6.0) - i\n",
        "    p = v * (1.0 - s)\n",
        "    q = v * (1.0 - s * f)\n",
        "    t = v * (1.0 - s * (1.0 - f))\n",
        "    i = i % 6\n",
        "    if i == 0: return v, t, p\n",
        "    if i == 1: return q, v, p\n",
        "    if i == 2: return p, v, t\n",
        "    if i == 3: return p, q, v\n",
        "    if i == 4: return t, p, v\n",
        "    if i == 5: return v, p, q\n",
        "\n",
        "\n",
        "output_video_path = 'smooth_transition_video.mp4'\n",
        "generate_smooth_transition_video(output_video_path, resolution=(1920, 1080), duration=10, fps=30)"
      ],
      "metadata": {
        "id": "V1g1hkrcSLF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Implement a user-friends System to text input considering  manual input and file upload option\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_text_input():\n",
        "    print(\"Choose an option:\")\n",
        "    print(\"1. Manual Input\")\n",
        "    print(\"2. File Upload\")\n",
        "\n",
        "    option = input(\"Enter the option number: \")\n",
        "\n",
        "    if option == '1':\n",
        "        return manual_input()\n",
        "    elif option == '2':\n",
        "        return file_upload()\n",
        "    else:\n",
        "        print(\"Invalid option. Please choose 1 or 2.\")\n",
        "        return get_text_input()\n",
        "\n",
        "def manual_input():\n",
        "    return input(\"Enter your text: \")\n",
        "\n",
        "def file_upload():\n",
        "    file_path = input(\"Enter the path to the file: \")\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please enter a valid file path.\")\n",
        "        return file_upload()\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading the file: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    text_input = get_text_input()\n",
        "\n",
        "    if text_input:\n",
        "        print(\"\\nYour input:\")\n",
        "        print(text_input)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "37IeUNjnSLNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##Provide user with option to customize visual element such as front color. and background\n",
        "import colorama\n",
        "from colorama import Fore, Style\n",
        "\n",
        "def get_text_input():\n",
        "    print(\"Choose an option:\")\n",
        "    print(\"1. Manual Input\")\n",
        "    print(\"2. File Upload\")\n",
        "\n",
        "    option = input(\"Enter the option number: \")\n",
        "\n",
        "    if option == '1':\n",
        "        return manual_input()\n",
        "    elif option == '2':\n",
        "        return file_upload()\n",
        "    else:\n",
        "        print(\"Invalid option. Please choose 1 or 2.\")\n",
        "        return get_text_input()\n",
        "\n",
        "def manual_input():\n",
        "    text_input = input(\"Enter your text: \")\n",
        "\n",
        "\n",
        "    font_color = input(\"Enter font color (e.g., red, green, blue): \")\n",
        "    background_color = input(\"Enter background color (e.g., white, yellow, magenta): \")\n",
        "\n",
        "    return format_text(text_input, font_color, background_color)\n",
        "\n",
        "def file_upload():\n",
        "    file_path = input(\"Enter the path to the file: \")\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            text_input = file.read()\n",
        "\n",
        "\n",
        "        font_color = input(\"Enter font color (e.g., red, green, blue): \")\n",
        "        background_color = input(\"Enter background color (e.g., white, yellow, magenta): \")\n",
        "\n",
        "        return format_text(text_input, font_color, background_color)\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please enter a valid file path.\")\n",
        "        return file_upload()\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading the file: {e}\")\n",
        "        return None\n",
        "\n",
        "def format_text(text, font_color, background_color):\n",
        "    colorama.init(autoreset=True)\n",
        "\n",
        "\n",
        "    color_code_map = {\n",
        "        'black': Fore.BLACK,\n",
        "        'red': Fore.RED,\n",
        "        'green': Fore.GREEN,\n",
        "        'yellow': Fore.YELLOW,\n",
        "        'blue': Fore.BLUE,\n",
        "        'magenta': Fore.MAGENTA,\n",
        "        'cyan': Fore.CYAN,\n",
        "        'white': Fore.WHITE\n",
        "    }\n",
        "\n",
        "    font_color_code = color_code_map.get(font_color.lower(), Fore.RESET)\n",
        "    background_color_code = color_code_map.get(background_color.lower(), Fore.RESET)\n",
        "\n",
        "    formatted_text = f\"{background_color_code}{font_color_code}{text}{Fore.RESET}\"\n",
        "\n",
        "    return formatted_text\n",
        "\n",
        "def main():\n",
        "    text_input = get_text_input()\n",
        "\n",
        "    if text_input:\n",
        "        print(\"\\nYour formatted input:\")\n",
        "        print(text_input)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "5tOkzUThXFSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######   Detial  if audio integration. such as background music or voiceover should be include in the generated video\n",
        "###\n",
        "\n",
        "\n",
        "from moviepy.editor import VideoClip, TextClip, AudioFileClip\n",
        "from moviepy.audio.io.ffmpeg_audiowriter import FFMPEG_AudioWriter\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "\n",
        "def generate_video_with_audio(output_path, text, background_music_path, voiceover_path):\n",
        "    # Create a text clip\n",
        "    text_clip = TextClip(text, fontsize=30, color='white', bg_color='black', size=(640, 480))\n",
        "\n",
        "    background_music = AudioFileClip(background_music_path)\n",
        "\n",
        "\n",
        "    voiceover = AudioFileClip(voiceover_path)\n",
        "\n",
        "    video_duration = max(background_music.duration, voiceover.duration)\n",
        "    text_clip = text_clip.set_duration(video_duration)\n",
        "\n",
        "\n",
        "    video_clip = text_clip.set_audio(background_music.subclip(0, text_clip.duration))\n",
        "    video_clip = video_clip.set_audio(video_clip.audio.set_audio(voiceover.subclip(0, text_clip.duration)))\n",
        "\n",
        "\n",
        "    video_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "\n",
        "output_video_path = 'output_video_with_audio.mp4'\n",
        "text_to_display = 'Hello, this is a generated video!'\n",
        "background_music_file_path = 'background_music.mp3'\n",
        "voiceover_file_path = 'voiceover.mp3'\n",
        "\n",
        "generate_video_with_audio(output_video_path, text_to_display, background_music_file_path, voiceover_file_path)"
      ],
      "metadata": {
        "id": "J8ydrdusX7cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #### Determine addition output format or file type to support along side video\n",
        "\n",
        "from moviepy.editor import VideoClip, TextClip, AudioFileClip\n",
        "\n",
        "def generate_video_with_audio(output_path, text, background_music_path, voiceover_path, output_format='mp4'):\n",
        "\n",
        "    text_clip = TextClip(text, fontsize=30, color='white', bg_color='black', size=(640, 480))\n",
        "\n",
        "\n",
        "    background_music = AudioFileClip(background_music_path)\n",
        "\n",
        "\n",
        "    voiceover = AudioFileClip(voiceover_path)\n",
        "\n",
        "\n",
        "    video_duration = max(background_music.duration, voiceover.duration)\n",
        "    text_clip = text_clip.set_duration(video_duration)\n",
        "\n",
        "    video_clip = text_clip.set_audio(background_music.subclip(0, text_clip.duration))\n",
        "    video_clip = video_clip.set_audio(video_clip.audio.set_audio(voiceover.subclip(0, text_clip.duration)))\n",
        "\n",
        "\n",
        "    if output_format.lower() == 'mp4':\n",
        "        video_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
        "    elif output_format.lower() == 'avi':\n",
        "        video_clip.write_videofile(output_path, codec=\"rawvideo\", audio_codec=\"pcm_s16le\")\n",
        "    else:\n",
        "        print(f\"Unsupported output format: {output_format}\")\n",
        "\n",
        "output_video_path_mp4 = 'output_video_with_audio.mp4'\n",
        "output_video_path_avi = 'output_video_with_audio.avi'\n",
        "text_to_display = 'Hello, this is a generated video!'\n",
        "background_music_file_path = 'background_music.mp3'\n",
        "voiceover_file_path = 'voiceover.mp3'\n",
        "\n",
        "generate_video_with_audio(output_video_path_mp4, text_to_display, background_music_file_path, voiceover_file_path, output_format='mp4')\n",
        "generate_video_with_audio(output_video_path_avi, text_to_display, background_music_file_path, voiceover_file_path, output_format='avi')"
      ],
      "metadata": {
        "id": "DtoUxFWUX7sz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}