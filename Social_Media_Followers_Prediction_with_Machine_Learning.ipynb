{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anchayadav/AutoTS/blob/main/Social_Media_Followers_Prediction_with_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "lpudqz3_Rr_c",
        "outputId": "0ddc1c83-ef25-417a-f9f1-955f7077e4ac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-14999754-f54a-406a-bb03-9a6fed8a11b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>period_start</th>\n",
              "      <th>period_end</th>\n",
              "      <th>followers_gained</th>\n",
              "      <th>followers_lost</th>\n",
              "      <th>followers_net</th>\n",
              "      <th>followers_total</th>\n",
              "      <th>subscribers_gained</th>\n",
              "      <th>subscribers_lost</th>\n",
              "      <th>subscribers_net</th>\n",
              "      <th>subscribers_total</th>\n",
              "      <th>views</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5/1/2020</td>\n",
              "      <td>5/31/2020</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>128.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6/1/2020</td>\n",
              "      <td>6/30/2020</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7/1/2020</td>\n",
              "      <td>7/31/2020</td>\n",
              "      <td>103</td>\n",
              "      <td>0</td>\n",
              "      <td>103</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14616.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8/1/2020</td>\n",
              "      <td>8/31/2020</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>158</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4053.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9/1/2020</td>\n",
              "      <td>9/30/2020</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>192</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5153.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14999754-f54a-406a-bb03-9a6fed8a11b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14999754-f54a-406a-bb03-9a6fed8a11b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14999754-f54a-406a-bb03-9a6fed8a11b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-55847cd7-4ca3-4a90-bce6-d17f705fafaf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55847cd7-4ca3-4a90-bce6-d17f705fafaf')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-55847cd7-4ca3-4a90-bce6-d17f705fafaf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  period_start period_end  followers_gained  followers_lost  followers_net  \\\n",
              "0     5/1/2020  5/31/2020                 1               0              1   \n",
              "1     6/1/2020  6/30/2020                 8               0              8   \n",
              "2     7/1/2020  7/31/2020               103               0            103   \n",
              "3     8/1/2020  8/31/2020                46               0             46   \n",
              "4     9/1/2020  9/30/2020                35               1             34   \n",
              "\n",
              "   followers_total  subscribers_gained  subscribers_lost  subscribers_net  \\\n",
              "0                1                   0                 0                0   \n",
              "1                9                   0                 0                0   \n",
              "2              112                   0                 0                0   \n",
              "3              158                   0                 0                0   \n",
              "4              192                   0                 0                0   \n",
              "\n",
              "   subscribers_total    views  \n",
              "0                  0    128.0  \n",
              "1                  0  16130.0  \n",
              "2                  0  14616.0  \n",
              "3                  0   4053.0  \n",
              "4                  0   5153.0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "data=pd.read_csv('stats.csv')\n",
        "data.drop(data.tail(1).index,inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "wRoOuSX-SF6S",
        "outputId": "21396567-1c09-4eca-dd70-e7120118ded7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.set_theme(style='whitegrid')\n",
        "plt.title(\"number of the followers I gained Every Month\")\n",
        "sns.barplot(x=\"followers_gained\",y=\"period_end\",data=data)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "Kbf4MqBtSF8i",
        "outputId": "01568754-4efd-41ef-b3b9-4b71c3def7d5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.set_theme(style='whitegrid')\n",
        "plt.title(\"number of the followers I gained Every Month\")\n",
        "sns.barplot(x=\"followers_total\",y=\"period_end\",data=data)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "g39kUbB2SF_U",
        "outputId": "74d4daf4-06ca-435b-e41a-166d43d250ff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.set_theme(style='whitegrid')\n",
        "plt.title(\"number of the followers I gained Every Month\")\n",
        "sns.barplot(x=\"views\",y=\"period_end\",data=data)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMgQixslSGCw",
        "outputId": "41b6f58d-be79-4666-a266-f8f09868b631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting autots\n",
            "  Downloading autots-0.6.1-py3-none-any.whl (777 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/777.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/777.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.4/777.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.10/dist-packages (from autots) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from autots) (1.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from autots) (0.14.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from autots) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->autots) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->autots) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->autots) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->autots) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->autots) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.10.0->autots) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.10.0->autots) (23.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels>=0.10.0->autots) (1.16.0)\n",
            "Installing collected packages: autots\n",
            "Successfully installed autots-0.6.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install autots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH_ztT6RUOT3",
        "outputId": "1e4aea58-993f-4344-fd8e-a95666c7cccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data frequency is: M, used frequency is: M\n",
            "Model Number: 1 with model ARIMA in generation 0 of 10\n",
            "Model Number: 2 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 3 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 4 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 5 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 6 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 7 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 8 with model DatepartRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 12s 12s/step - loss: 0.3676\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3768\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3675\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3665\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3587\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3633\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3659\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3596\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3549\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3627\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3585\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3509\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3577\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3547\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3512\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3440\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3469\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3570\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3534\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3475\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3543\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3426\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3390\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3294\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3457\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3405\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3341\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3598\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3293\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3427\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3373\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3267\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3246\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3267\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3326\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3140\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3365\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3223\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3222\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3110\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3228\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3362\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3161\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3174\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2948\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3026\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2891\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3140\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3028\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7cb32397f9a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Model Number: 9 with model ETS in generation 0 of 10\n",
            "Model Number: 10 with model ETS in generation 0 of 10\n",
            "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "ETS failed on First with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "Model Number: 11 with model GLM in generation 0 of 10\n",
            "Model Number: 12 with model GLM in generation 0 of 10\n",
            "Model Number: 13 with model GLS in generation 0 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1257: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 14 with model GLS in generation 0 of 10\n",
            "Model Number: 15 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 15 in generation 0: GluonTS\n",
            "Model Number: 16 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 16 in generation 0: GluonTS\n",
            "Model Number: 17 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 17 in generation 0: GluonTS\n",
            "Model Number: 18 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 18 in generation 0: GluonTS\n",
            "Model Number: 19 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 19 in generation 0: GluonTS\n",
            "Model Number: 20 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 21 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 22 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 23 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 24 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 25 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 26 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 27 with model UnobservedComponents in generation 0 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 28 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 29 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 30 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
            "Model Number: 31 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
            "Model Number: 32 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
            "Model Number: 33 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
            "Model Number: 34 with model WindowRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by MLPRegressor.') in model 34 in generation 0: WindowRegression\n",
            "Model Number: 35 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 36 with model FBProphet in generation 0 of 10\n",
            "Model Number: 37 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 37 in generation 0: GluonTS\n",
            "Model Number: 38 with model MultivariateRegression in generation 0 of 10\n",
            "Model Number: 39 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 39 in generation 0: MultivariateRegression\n",
            "Model Number: 40 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 40 in generation 0: DatepartRegression\n",
            "Model Number: 41 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 42 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 43 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 44 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 45 with model ETS in generation 0 of 10\n",
            "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "ETS failed on First with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "Model Number: 46 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
            "Model Number: 47 with model ARDL in generation 0 of 10\n",
            "Model Number: 48 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 48 in generation 0: MultivariateMotif\n",
            "Model Number: 49 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 49 in generation 0: MultivariateMotif\n",
            "Model Number: 50 with model UnivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 50 in generation 0: UnivariateMotif\n",
            "Model Number: 51 with model UnivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 51 in generation 0: UnivariateMotif\n",
            "Model Number: 52 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('zero-size array to reduction operation fmax which has no identity') in model 52 in generation 0: SectionalMotif\n",
            "Model Number: 53 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('kth(=10) out of bounds (3)') in model 53 in generation 0: SectionalMotif\n",
            "Model Number: 54 with model MultivariateRegression in generation 0 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 55 with model FBProphet in generation 0 of 10\n",
            "Model Number: 56 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 57 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 58 with model NVAR in generation 0 of 10\n",
            "Model Number: 59 with model Theta in generation 0 of 10\n",
            "Template Eval Error: ValueError('x must have 2 complete cycles requires 24 observations. x only has 11 observation(s)') in model 59 in generation 0: Theta\n",
            "Model Number: 60 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
            "Model Number: 61 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
            "Model Number: 62 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 63 with model LastValueNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 63 in generation 0: LastValueNaive\n",
            "Model Number: 64 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 65 with model GLS in generation 0 of 10\n",
            "Model Number: 66 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 67 with model GLM in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 67 in generation 0: GLM\n",
            "Model Number: 68 with model ETS in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 68 in generation 0: ETS\n",
            "Model Number: 69 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: divide by zero encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:66: RuntimeWarning: invalid value encountered in divide\n",
            "  post_mu = (\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 69 in generation 0: FBProphet\n",
            "Model Number: 70 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 70 in generation 0: GluonTS\n",
            "Model Number: 71 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 71 in generation 0: UnobservedComponents\n",
            "Model Number: 72 with model VAR in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 72 in generation 0: VAR\n",
            "Model Number: 73 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 73 in generation 0: VECM\n",
            "Model Number: 74 with model ARIMA in generation 0 of 10\n",
            "Model Number: 75 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 76 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 77 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 77 in generation 0: UnivariateRegression\n",
            "Model Number: 78 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 78 in generation 0: MultivariateRegression\n",
            "Model Number: 79 with model UnivariateMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RobustScaler failed on fit') in model 79 in generation 0: UnivariateMotif\n",
            "Model Number: 80 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 80 in generation 0: MultivariateMotif\n",
            "Model Number: 81 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('XA and XB must have the same number of columns (i.e. feature dimension.)') in model 81 in generation 0: SectionalMotif\n",
            "Model Number: 82 with model NVAR in generation 0 of 10\n",
            "Model Number: 83 with model Theta in generation 0 of 10\n",
            "Template Eval Error: ValueError('x must have 2 complete cycles requires 24 observations. x only has 11 observation(s)') in model 83 in generation 0: Theta\n",
            "Model Number: 84 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 84 in generation 0: ARDL\n",
            "Model Number: 85 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
            "Model Number: 86 with model MetricMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 86 in generation 0: MetricMotif\n",
            "Model Number: 87 with model NVAR in generation 0 of 10\n",
            "Model Number: 88 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 88 in generation 0: ARDL\n",
            "Model Number: 89 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 89 in generation 0: SectionalMotif\n",
            "Model Number: 90 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 91 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 91 in generation 0: ARCH\n",
            "Model Number: 92 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 92 in generation 0: ARDL\n",
            "Model Number: 93 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 93 in generation 0: UnivariateRegression\n",
            "Model Number: 94 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 94 in generation 0: DatepartRegression\n",
            "Model Number: 95 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 95 in generation 0: VAR\n",
            "Model Number: 96 with model GLS in generation 0 of 10\n",
            "Model Number: 97 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 97 in generation 0: ARCH\n",
            "Model Number: 98 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 99 with model UnivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 99 in generation 0: UnivariateMotif\n",
            "Model Number: 100 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 100 in generation 0: MultivariateMotif\n",
            "Model Number: 101 with model MetricMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 101 in generation 0: MetricMotif\n",
            "Model Number: 102 with model ARIMA in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 102 in generation 0: ARIMA\n",
            "Model Number: 103 with model ETS in generation 0 of 10\n",
            "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "ETS failed on First with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "Model Number: 104 with model NVAR in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 104 in generation 0: NVAR\n",
            "Model Number: 105 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 105 in generation 0: ARCH\n",
            "Model Number: 106 with model GLS in generation 0 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: divide by zero encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 107 with model UnivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 107 in generation 0: UnivariateMotif\n",
            "Model Number: 108 with model MetricMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 108 in generation 0: MetricMotif\n",
            "Model Number: 109 with model LastValueNaive in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'CumSumTransformer', '1': 'KalmanSmoothing', '2': 'ScipyFilter', '3': 'AlignLastValue', '4': 'PositiveShift'}, 'transformation_params': {'0': {}, '1': {'model_name': 'MA', 'state_transition': [[1, 0], [1, 0]], 'process_noise': [[0.2, 0.0], [0.0, 0]], 'observation_model': [[1, 0.1]], 'observation_noise': 1.0, 'em_iter': None}, '2': {'method': 'savgol_filter', 'method_args': {'window_length': 7, 'polyorder': 3, 'deriv': 0, 'mode': 'interp'}}, '3': {'rows': 7, 'lag': 28, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '4': {}}}. fail_on_forecast_nan=True\") in model 109 in generation 0: LastValueNaive\n",
            "Model Number: 110 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 110 in generation 0: MultivariateMotif\n",
            "Model Number: 111 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 111 in generation 0: GluonTS\n",
            "Model Number: 112 with model GLM in generation 0 of 10\n",
            "Model Number: 113 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 113 in generation 0: GLM\n",
            "Model Number: 114 with model GLS in generation 0 of 10\n",
            "Model Number: 115 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 116 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 116 in generation 0: ARDL"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1257: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: divide by zero encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:66: RuntimeWarning: invalid value encountered in divide\n",
            "  post_mu = (\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:188: RuntimeWarning: invalid value encountered in divide\n",
            "  return np.sum(resid_dev * freq_weights * var_weights / scale)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Number: 117 with model SeasonalNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 117 in generation 0: SeasonalNaive\n",
            "Model Number: 118 with model Theta in generation 0 of 10\n",
            "Model Number: 119 with model NVAR in generation 0 of 10\n",
            "Model Number: 120 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 120 in generation 0: UnobservedComponents\n",
            "Model Number: 121 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 122 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 123 with model MetricMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 123 in generation 0: MetricMotif\n",
            "Model Number: 124 with model ConstantNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 124 in generation 0: ConstantNaive\n",
            "Model Number: 125 with model Theta in generation 0 of 10\n",
            "Template Eval Error: ValueError('x must have 2 complete cycles requires 24 observations. x only has 11 observation(s)') in model 125 in generation 0: Theta\n",
            "Model Number: 126 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 126 in generation 0: MultivariateMotif\n",
            "Model Number: 127 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 128 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 128 in generation 0: SectionalMotif\n",
            "Model Number: 129 with model LastValueNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 129 in generation 0: LastValueNaive\n",
            "Model Number: 130 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 130 in generation 0: MultivariateMotif\n",
            "Model Number: 131 with model GLM in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 131 in generation 0: GLM\n",
            "Model Number: 132 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('kth(=10) out of bounds (3)') in model 132 in generation 0: MultivariateMotif\n",
            "Model Number: 133 with model NVAR in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 133 in generation 0: NVAR\n",
            "Model Number: 134 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (10) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (7).') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0\\n2020-12-31             0.0\\n2021-01-31             0.0\\n2021-02-28             0.0\\n2021-03-31             0.0 and predict             HolidayFlag_US\\n2021-04-30             0.0\\n2021-05-31             1.0\\n2021-06-30             0.0\\n2021-07-31             0.0\") in model 134 in generation 0: ARDL\n",
            "Model Number: 135 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 135 in generation 0: VECM\n",
            "Model Number: 136 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 137 with model GLS in generation 0 of 10\n",
            "Model Number: 138 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 138 in generation 0: ARCH\n",
            "Model Number: 139 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 140 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 141 with model GLM in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 141 in generation 0: GLM\n",
            "Model Number: 142 with model MetricMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 142 in generation 0: MetricMotif\n",
            "Model Number: 143 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 143 in generation 0: MultivariateMotif\n",
            "Model Number: 144 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 144 in generation 0: UnobservedComponents\n",
            "Model Number: 145 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 145 in generation 0: ARCH\n",
            "Model Number: 146 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (46) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (10).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nperiod_end                                                                    \\n2020-05-31        1        2  2459000.5      0.0      0.0      0.0      0.0   \\n2020-06-30        0        2  2459030.5      0.0      0.0      0.0      0.0   \\n2020-07-31        0        3  2459061.5      0.0      0.0      0.0      0.0   \\n2020-08-31        0        3  2459092.5      0.0      0.0      0.0      0.0   \\n2020-09-30        0        3  2459122.5      0.0      0.0      0.0      0.0   \\n2020-10-31        1        4  2459153.5      0.0      0.0      0.0      0.0   \\n2020-11-30        0        4  2459183.5      0.0      0.0      0.0      0.0   \\n2020-12-31        0        4  2459214.5      0.0      0.0      0.0      0.0   \\n2021-01-31        1        1  2459245.5      1.0      0.0      0.0      0.0   \\n2021-02-28        1        1  2459273.5      0.0      1.0      0.0      0.0   \\n2021-03-31        0        1  2459304.5      0.0      0.0      1.0      0.0   \\n\\n            month_5  month_6  month_7  ...  month_10  month_11  month_12  \\\\\\nperiod_end                             ...                                 \\n2020-05-31      1.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2020-06-30      0.0      1.0      0.0  ...       0.0       0.0       0.0   \\n2020-07-31      0.0      0.0      1.0  ...       0.0       0.0       0.0   \\n2020-08-31      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2020-09-30      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2020-10-31      0.0      0.0      0.0  ...       1.0       0.0       0.0   \\n2020-11-30      0.0      0.0      0.0  ...       0.0       1.0       0.0   \\n2020-12-31      0.0      0.0      0.0  ...       0.0       0.0       1.0   \\n2021-01-31      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2021-02-28      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2021-03-31      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n\\n            weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\\\\nperiod_end                                                                     \\n2020-05-31        0.0        0.0        0.0        0.0        0.0        0.0   \\n2020-06-30        0.0        1.0        0.0        0.0        0.0        0.0   \\n2020-07-31        0.0        0.0        0.0        0.0        1.0        0.0   \\n2020-08-31        1.0        0.0        0.0        0.0        0.0        0.0   \\n2020-09-30        0.0        0.0        1.0        0.0        0.0        0.0   \\n2020-10-31        0.0        0.0        0.0        0.0        0.0        1.0   \\n2020-11-30        1.0        0.0        0.0        0.0        0.0        0.0   \\n2020-12-31        0.0        0.0        0.0        1.0        0.0        0.0   \\n2021-01-31        0.0        0.0        0.0        0.0        0.0        0.0   \\n2021-02-28        0.0        0.0        0.0        0.0        0.0        0.0   \\n2021-03-31        0.0        0.0        1.0        0.0        0.0        0.0   \\n\\n            weekday_6  \\nperiod_end             \\n2020-05-31        1.0  \\n2020-06-30        0.0  \\n2020-07-31        0.0  \\n2020-08-31        0.0  \\n2020-09-30        0.0  \\n2020-10-31        0.0  \\n2020-11-30        0.0  \\n2020-12-31        0.0  \\n2021-01-31        1.0  \\n2021-02-28        1.0  \\n2021-03-31        0.0  \\n\\n[11 rows x 22 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2021-04-30        0        2  2459334.5      0.0      0.0      0.0      1.0   \\n2021-05-31        0        2  2459365.5      0.0      0.0      0.0      0.0   \\n2021-06-30        0        2  2459395.5      0.0      0.0      0.0      0.0   \\n2021-07-31        1        3  2459426.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  month_10  month_11  month_12  \\\\\\n2021-04-30      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2021-05-31      1.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2021-06-30      0.0      1.0      0.0  ...       0.0       0.0       0.0   \\n2021-07-31      0.0      0.0      1.0  ...       0.0       0.0       0.0   \\n\\n            weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\\\\n2021-04-30        0.0        0.0        0.0        0.0        1.0        0.0   \\n2021-05-31        1.0        0.0        0.0        0.0        0.0        0.0   \\n2021-06-30        0.0        0.0        1.0        0.0        0.0        0.0   \\n2021-07-31        0.0        0.0        0.0        0.0        0.0        1.0   \\n\\n            weekday_6  \\n2021-04-30        0.0  \\n2021-05-31        0.0  \\n2021-06-30        0.0  \\n2021-07-31        0.0  \\n\\n[4 rows x 22 columns]\") in model 146 in generation 0: ARDL\n",
            "Model Number: 147 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 148 with model ARIMA in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 148 in generation 0: ARIMA\n",
            "Model Number: 149 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('zero-size array to reduction operation fmax which has no identity') in model 149 in generation 0: SectionalMotif\n",
            "Model Number: 150 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 150 in generation 0: MultivariateMotif\n",
            "Model Number: 151 with model ConstantNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 151 in generation 0: ConstantNaive\n",
            "Model Number: 152 with model NVAR in generation 0 of 10\n",
            "Model Number: 153 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('zero-size array to reduction operation fmax which has no identity') in model 153 in generation 0: SectionalMotif\n",
            "Model Number: 154 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 154 in generation 0: MultivariateMotif\n",
            "Model Number: 155 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('XA and XB must have the same number of columns (i.e. feature dimension.)') in model 155 in generation 0: SectionalMotif\n",
            "Model Number: 156 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 156 in generation 0: UnivariateRegression\n",
            "Model Number: 157 with model ARIMA in generation 0 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 158 with model NVAR in generation 0 of 10\n",
            "Model Number: 159 with model UnivariateMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 159 in generation 0: UnivariateMotif\n",
            "Model Number: 160 with model GLS in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'rolling_mean', 'transformations': {'0': 'StandardScaler', '1': 'AlignLastValue', '2': 'HolidayTransformer', '3': 'SeasonalDifference', '4': 'RobustScaler', '5': 'AlignLastValue'}, 'transformation_params': {'0': {}, '1': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}, '2': {'threshold': 0.9, 'splash_threshold': None, 'use_dayofmonth_holidays': True, 'use_wkdom_holidays': True, 'use_wkdeom_holidays': False, 'use_lunar_holidays': False, 'use_lunar_weekday': False, 'use_islamic_holidays': False, 'use_hebrew_holidays': False, 'anomaly_detector_params': {'method': 'IQR', 'method_params': {'iqr_threshold': 2.0, 'iqr_quantiles': [0.25, 0.75]}, 'fillna': 'ffill', 'transform_dict': {'transformations': {'0': 'DatepartRegression'}, 'transformation_params': {'0': {'datepart_method': 'simple_3', 'regression_model': {'model': 'DecisionTree', 'model_params': {'max_depth': None, 'min_samples_split': 0.1}}}}}}, 'remove_excess_anomalies': True, 'impact': 'datepart_regression', 'regression_params': {'regression_model': {'model': 'ElasticNet', 'model_params': {}}, 'datepart_method': 'recurring', 'polynomial_degree': None, 'transform_dict': None, 'holiday_countries_used': False}}, '3': {'lag_1': 7, 'method': 'LastValue'}, '4': {}, '5': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}}}. fail_on_forecast_nan=True\") in model 160 in generation 0: GLS\n",
            "Model Number: 161 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 161 in generation 0: MultivariateMotif\n",
            "Model Number: 162 with model UnobservedComponents in generation 0 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 163 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 163 in generation 0: ARDL\n",
            "Model Number: 164 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 164 in generation 0: ARCH\n",
            "Model Number: 165 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('zero-size array to reduction operation fmax which has no identity') in model 165 in generation 0: SectionalMotif\n",
            "Model Number: 166 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 166 in generation 0: ARCH\n",
            "Model Number: 167 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 168 with model SeasonalNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 168 in generation 0: SeasonalNaive\n",
            "Model Number: 169 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 169 in generation 0: MultivariateMotif\n",
            "Model Number: 170 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 10)) while a minimum of 1 is required by check_pairwise_arrays.') in model 170 in generation 0: SectionalMotif\n",
            "Model Number: 171 with model ETS in generation 0 of 10\n",
            "Model Number: 172 with model WindowRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by AdaBoostRegressor.') in model 172 in generation 0: WindowRegression\n",
            "Model Number: 173 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 174 with model ARIMA in generation 0 of 10\n",
            "Model Number: 175 with model ARIMA in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 175 in generation 0: ARIMA\n",
            "Model Number: 176 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 177 with model ARIMA in generation 0 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 178 with model UnivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 178 in generation 0: UnivariateMotif\n",
            "Model Number: 179 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 180 with model UnivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 180 in generation 0: UnivariateMotif\n",
            "Model Number: 181 with model LastValueNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 181 in generation 0: LastValueNaive\n",
            "Model Number: 182 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 182 in generation 0: VAR\n",
            "Model Number: 183 with model SeasonalNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 183 in generation 0: SeasonalNaive\n",
            "Model Number: 184 with model ConstantNaive in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'PositiveShift', '1': 'LevelShiftTransformer', '2': 'MaxAbsScaler', '3': 'AlignLastValue', '4': 'PowerTransformer', '5': 'CumSumTransformer'}, 'transformation_params': {'0': {}, '1': {'window_size': 90, 'alpha': 3.5, 'grouping_forward_limit': 2, 'max_level_shifts': 5, 'alignment': 'average'}, '2': {}, '3': {'rows': 2, 'lag': 28, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '4': {}, '5': {}}}. fail_on_forecast_nan=True\") in model 184 in generation 0: ConstantNaive\n",
            "Model Number: 185 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 186 with model WindowRegression in generation 0 of 10\n",
            "New Generation: 1 of 10\n",
            "Model Number: 187 with model GLS in generation 1 of 10\n",
            "Model Number: 188 with model GLS in generation 1 of 10\n",
            "Model Number: 189 with model GLS in generation 1 of 10\n",
            "Model Number: 190 with model GLS in generation 1 of 10\n",
            "Model Number: 191 with model GLS in generation 1 of 10\n",
            "Model Number: 192 with model GLS in generation 1 of 10\n",
            "Model Number: 193 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 194 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 195 with model ConstantNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 195 in generation 1: ConstantNaive\n",
            "Model Number: 196 with model NVAR in generation 1 of 10\n",
            "Model Number: 197 with model NVAR in generation 1 of 10\n",
            "Model Number: 198 with model NVAR in generation 1 of 10\n",
            "Model Number: 199 with model Theta in generation 1 of 10\n",
            "Model Number: 200 with model Theta in generation 1 of 10\n",
            "Model Number: 201 with model Theta in generation 1 of 10\n",
            "Model Number: 202 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 203 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 203 in generation 1: DatepartRegression\n",
            "Model Number: 204 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 205 with model NVAR in generation 1 of 10\n",
            "Model Number: 206 with model NVAR in generation 1 of 10\n",
            "Model Number: 207 with model NVAR in generation 1 of 10\n",
            "Model Number: 208 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 209 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 210 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 211 with model NVAR in generation 1 of 10\n",
            "Model Number: 212 with model NVAR in generation 1 of 10\n",
            "Model Number: 213 with model NVAR in generation 1 of 10\n",
            "Model Number: 214 with model AverageValueNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 214 in generation 1: AverageValueNaive\n",
            "Model Number: 215 with model AverageValueNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 215 in generation 1: AverageValueNaive\n",
            "Model Number: 216 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 217 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 218 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 219 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 220 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 221 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 222 with model UnobservedComponents in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 222 in generation 1: UnobservedComponents\n",
            "Model Number: 223 with model UnobservedComponents in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 223 in generation 1: UnobservedComponents\n",
            "Model Number: 224 with model UnobservedComponents in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 224 in generation 1: UnobservedComponents\n",
            "Model Number: 225 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 226 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 226 in generation 1: DatepartRegression\n",
            "Model Number: 227 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 228 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 229 with model UnobservedComponents in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 229 in generation 1: UnobservedComponents\n",
            "Model Number: 230 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 231 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 232 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 232 in generation 1: DatepartRegression\n",
            "Model Number: 233 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 234 with model ConstantNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 234 in generation 1: ConstantNaive\n",
            "Model Number: 235 with model ConstantNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 235 in generation 1: ConstantNaive\n",
            "Model Number: 236 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 237 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 238 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 239 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 240 with model LastValueNaive in generation 1 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 241 with model GLS in generation 1 of 10\n",
            "Model Number: 242 with model GLS in generation 1 of 10\n",
            "Model Number: 243 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 244 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 245 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 246 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 247 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 248 with model FBProphet in generation 1 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 249 with model FBProphet in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 249 in generation 1: FBProphet\n",
            "Model Number: 250 with model NVAR in generation 1 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (5). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 251 with model NVAR in generation 1 of 10\n",
            "Model Number: 252 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 252 in generation 1: DatepartRegression\n",
            "Model Number: 253 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 254 with model AverageValueNaive in generation 1 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "  warnings.warn(empty_warning_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 255 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 256 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 257 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 258 with model ETS in generation 1 of 10\n",
            "Model Number: 259 with model ETS in generation 1 of 10\n",
            "Model Number: 260 with model FBProphet in generation 1 of 10\n",
            "Model Number: 261 with model FBProphet in generation 1 of 10\n",
            "Model Number: 262 with model SeasonalNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer QuantileTransformer failed on fit') in model 262 in generation 1: SeasonalNaive\n",
            "Model Number: 263 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 264 with model DatepartRegression in generation 1 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/window_functions.py:468: RuntimeWarning: invalid value encountered in divide\n",
            "  slope = (sxy - sx * sy) / (sx2 - sx**2)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1559: RuntimeWarning: All-NaN slice encountered\n",
            "  r, k = function_base._ureduce(a,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 265 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 266 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 267 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 268 with model GLS in generation 1 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 269 with model GLS in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 269 in generation 1: GLS\n",
            "Model Number: 270 with model ETS in generation 1 of 10\n",
            "Model Number: 271 with model ETS in generation 1 of 10\n",
            "Model Number: 272 with model NVAR in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 272 in generation 1: NVAR\n",
            "Model Number: 273 with model NVAR in generation 1 of 10\n",
            "Model Number: 274 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 275 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 276 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 277 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 278 with model ARDL in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 278 in generation 1: ARDL\n",
            "Model Number: 279 with model ARDL in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (46) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (10).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nperiod_end                                                                    \\n2020-05-31        1        2  2459000.5      0.0      0.0      0.0      0.0   \\n2020-06-30        0        2  2459030.5      0.0      0.0      0.0      0.0   \\n2020-07-31        0        3  2459061.5      0.0      0.0      0.0      0.0   \\n2020-08-31        0        3  2459092.5      0.0      0.0      0.0      0.0   \\n2020-09-30        0        3  2459122.5      0.0      0.0      0.0      0.0   \\n2020-10-31        1        4  2459153.5      0.0      0.0      0.0      0.0   \\n2020-11-30        0        4  2459183.5      0.0      0.0      0.0      0.0   \\n2020-12-31        0        4  2459214.5      0.0      0.0      0.0      0.0   \\n2021-01-31        1        1  2459245.5      1.0      0.0      0.0      0.0   \\n2021-02-28        1        1  2459273.5      0.0      1.0      0.0      0.0   \\n2021-03-31        0        1  2459304.5      0.0      0.0      1.0      0.0   \\n\\n            month_5  month_6  month_7  ...  month_10  month_11  month_12  \\\\\\nperiod_end                             ...                                 \\n2020-05-31      1.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2020-06-30      0.0      1.0      0.0  ...       0.0       0.0       0.0   \\n2020-07-31      0.0      0.0      1.0  ...       0.0       0.0       0.0   \\n2020-08-31      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2020-09-30      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2020-10-31      0.0      0.0      0.0  ...       1.0       0.0       0.0   \\n2020-11-30      0.0      0.0      0.0  ...       0.0       1.0       0.0   \\n2020-12-31      0.0      0.0      0.0  ...       0.0       0.0       1.0   \\n2021-01-31      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2021-02-28      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2021-03-31      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n\\n            weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\\\\nperiod_end                                                                     \\n2020-05-31        0.0        0.0        0.0        0.0        0.0        0.0   \\n2020-06-30        0.0        1.0        0.0        0.0        0.0        0.0   \\n2020-07-31        0.0        0.0        0.0        0.0        1.0        0.0   \\n2020-08-31        1.0        0.0        0.0        0.0        0.0        0.0   \\n2020-09-30        0.0        0.0        1.0        0.0        0.0        0.0   \\n2020-10-31        0.0        0.0        0.0        0.0        0.0        1.0   \\n2020-11-30        1.0        0.0        0.0        0.0        0.0        0.0   \\n2020-12-31        0.0        0.0        0.0        1.0        0.0        0.0   \\n2021-01-31        0.0        0.0        0.0        0.0        0.0        0.0   \\n2021-02-28        0.0        0.0        0.0        0.0        0.0        0.0   \\n2021-03-31        0.0        0.0        1.0        0.0        0.0        0.0   \\n\\n            weekday_6  \\nperiod_end             \\n2020-05-31        1.0  \\n2020-06-30        0.0  \\n2020-07-31        0.0  \\n2020-08-31        0.0  \\n2020-09-30        0.0  \\n2020-10-31        0.0  \\n2020-11-30        0.0  \\n2020-12-31        0.0  \\n2021-01-31        1.0  \\n2021-02-28        1.0  \\n2021-03-31        0.0  \\n\\n[11 rows x 22 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2021-04-30        0        2  2459334.5      0.0      0.0      0.0      1.0   \\n2021-05-31        0        2  2459365.5      0.0      0.0      0.0      0.0   \\n2021-06-30        0        2  2459395.5      0.0      0.0      0.0      0.0   \\n2021-07-31        1        3  2459426.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  month_10  month_11  month_12  \\\\\\n2021-04-30      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2021-05-31      1.0      0.0      0.0  ...       0.0       0.0       0.0   \\n2021-06-30      0.0      1.0      0.0  ...       0.0       0.0       0.0   \\n2021-07-31      0.0      0.0      1.0  ...       0.0       0.0       0.0   \\n\\n            weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\\\\n2021-04-30        0.0        0.0        0.0        0.0        1.0        0.0   \\n2021-05-31        1.0        0.0        0.0        0.0        0.0        0.0   \\n2021-06-30        0.0        0.0        1.0        0.0        0.0        0.0   \\n2021-07-31        0.0        0.0        0.0        0.0        0.0        1.0   \\n\\n            weekday_6  \\n2021-04-30        0.0  \\n2021-05-31        0.0  \\n2021-06-30        0.0  \\n2021-07-31        0.0  \\n\\n[4 rows x 22 columns]\") in model 279 in generation 1: ARDL\n",
            "Model Number: 280 with model ETS in generation 1 of 10\n",
            "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "ETS failed on First with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "Model Number: 281 with model ETS in generation 1 of 10\n",
            "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "ETS failed on First with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "Model Number: 282 with model ConstantNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 282 in generation 1: ConstantNaive\n",
            "Model Number: 283 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 284 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 285 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 286 with model ETS in generation 1 of 10\n",
            "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "ETS failed on First with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "Model Number: 287 with model ETS in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 287 in generation 1: ETS\n",
            "Model Number: 288 with model GLM in generation 1 of 10\n",
            "Model Number: 289 with model ARIMA in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 289 in generation 1: ARIMA\n",
            "Model Number: 290 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 291 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 292 with model MultivariateRegression in generation 1 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Template Eval Error: AttributeError(\"'MLPRegressor' object has no attribute '_best_coefs'\") in model 292 in generation 1: MultivariateRegression\n",
            "Model Number: 293 with model GLM in generation 1 of 10\n",
            "Model Number: 294 with model GLS in generation 1 of 10\n",
            "Model Number: 295 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 296 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 297 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 298 with model ARIMA in generation 1 of 10\n",
            "Model Number: 299 with model ETS in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 299 in generation 1: ETS\n",
            "Model Number: 300 with model ARIMA in generation 1 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 301 with model ARIMA in generation 1 of 10\n",
            "Model Number: 302 with model ARIMA in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 302 in generation 1: ARIMA\n",
            "Model Number: 303 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 304 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 305 with model GLM in generation 1 of 10\n",
            "New Generation: 2 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 306 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 307 with model NVAR in generation 2 of 10\n",
            "Model Number: 308 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 309 with model NVAR in generation 2 of 10\n",
            "Model Number: 310 with model NVAR in generation 2 of 10\n",
            "Model Number: 311 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 312 with model NVAR in generation 2 of 10\n",
            "Model Number: 313 with model ARIMA in generation 2 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
            "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 314 with model GLM in generation 2 of 10\n",
            "Model Number: 315 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 316 with model NVAR in generation 2 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 317 with model GLS in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 317 in generation 2: GLS\n",
            "Model Number: 318 with model GLS in generation 2 of 10\n",
            "Model Number: 319 with model FBProphet in generation 2 of 10\n",
            "Model Number: 320 with model WindowRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nBayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 320 in generation 2: WindowRegression\n",
            "Model Number: 321 with model ARIMA in generation 2 of 10\n",
            "Model Number: 322 with model Theta in generation 2 of 10\n",
            "Model Number: 323 with model NVAR in generation 2 of 10\n",
            "Model Number: 324 with model GLS in generation 2 of 10\n",
            "Model Number: 325 with model AverageValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 325 in generation 2: AverageValueNaive\n",
            "Model Number: 326 with model ETS in generation 2 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on First with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 327 with model ARIMA in generation 2 of 10\n",
            "Model Number: 328 with model Theta in generation 2 of 10\n",
            "Model Number: 329 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 330 with model NVAR in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 330 in generation 2: NVAR\n",
            "Model Number: 331 with model GLM in generation 2 of 10\n",
            "Model Number: 332 with model MultivariateRegression in generation 2 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/_loss/link.py:172: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.log(y_pred, out=out)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 333 with model DatepartRegression in generation 2 of 10\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 7854.3594\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5121.7427\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3201.5444\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1966.0918\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1229.1066\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 807.9137\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 572.6454\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 354.2829\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 433.6544\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 925.8304\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 541.8711\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 652.6031\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 559.7010\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 511.6298\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 540.7673\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 575.2036\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 474.8171\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 484.6079\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 285.3752\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 666.3672\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 359.4751\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 552.9368\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 361.6949\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 533.4584\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 270.1610\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 559.0659\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 355.3567\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 618.8266\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 300.0541\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 561.0004\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 310.2385\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 541.8380\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 321.0781\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 613.6161\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 275.8243\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 432.5290\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 333.9095\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 521.7418\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 353.5482\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 584.7584\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 300.5489\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 530.1019\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 349.0216\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 565.3206\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 299.6323\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 514.0177\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 312.8511\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 499.6504\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 367.4886\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 535.1680\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 315.3774\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 571.7263\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 276.8292\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 463.6675\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 356.4334\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 536.3956\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 306.8984\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 487.8837\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 360.2920\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 524.0832\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 310.8222\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 561.5151\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 274.4135\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 455.2666\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 353.8180\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 527.9327\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 305.7659\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 480.5238\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 358.3835\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 516.9512\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 309.9636\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 470.4141\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 361.6140\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 510.1019\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 313.8186\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 548.4717\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 310.6982\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 541.1292\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 275.8991\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 384.8433\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 328.1809\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 554.7387\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 286.5628\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 497.3289\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 332.6459\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 537.7964\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 287.4946\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 490.0919\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 334.9181\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 530.5867\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 289.3509\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 483.6927\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 341.3560\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 520.3915\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 294.6268\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 474.3343\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 345.2441\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 514.1547\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 298.7871\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 492.0518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7cb323ea1c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 763ms/step\n",
            "Model Number: 334 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 335 with model FBProphet in generation 2 of 10\n",
            "Model Number: 336 with model UnobservedComponents in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 336 in generation 2: UnobservedComponents\n",
            "Model Number: 337 with model ETS in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 337 in generation 2: ETS\n",
            "Model Number: 338 with model NVAR in generation 2 of 10\n",
            "Model Number: 339 with model SeasonalNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 339 in generation 2: SeasonalNaive\n",
            "Model Number: 340 with model ETS in generation 2 of 10\n",
            "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "ETS failed on First with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "Model Number: 341 with model ARIMA in generation 2 of 10\n",
            "Model Number: 342 with model GLS in generation 2 of 10\n",
            "Model Number: 343 with model FBProphet in generation 2 of 10\n",
            "Model Number: 344 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 345 with model GLS in generation 2 of 10\n",
            "Model Number: 346 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 347 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 347 in generation 2: DatepartRegression\n",
            "Model Number: 348 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 349 with model MultivariateRegression in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 349 in generation 2: MultivariateRegression\n",
            "Model Number: 350 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 350 in generation 2: DatepartRegression\n",
            "Model Number: 351 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 352 with model ETS in generation 2 of 10\n",
            "Model Number: 353 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 354 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 355 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 355 in generation 2: DatepartRegression\n",
            "Model Number: 356 with model ETS in generation 2 of 10\n",
            "Model Number: 357 with model FBProphet in generation 2 of 10\n",
            "Model Number: 358 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 359 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 360 with model Theta in generation 2 of 10\n",
            "Model Number: 361 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 362 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 363 with model GLS in generation 2 of 10\n",
            "Model Number: 364 with model AverageValueNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 364 in generation 2: AverageValueNaive\n",
            "Model Number: 365 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 366 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 367 with model UnobservedComponents in generation 2 of 10\n",
            "Template Eval Error: LinAlgError('Singular matrix') in model 367 in generation 2: UnobservedComponents\n",
            "Model Number: 368 with model NVAR in generation 2 of 10\n",
            "Model Number: 369 with model GLS in generation 2 of 10\n",
            "Model Number: 370 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 371 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 372 with model NVAR in generation 2 of 10\n",
            "Model Number: 373 with model ARDL in generation 2 of 10\n",
            "Model Number: 374 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 375 with model ETS in generation 2 of 10\n",
            "Model Number: 376 with model WindowRegression in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 376 in generation 2: WindowRegression\n",
            "Model Number: 377 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 378 with model NVAR in generation 2 of 10\n",
            "Model Number: 379 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 380 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 381 with model GLS in generation 2 of 10\n",
            "Model Number: 382 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 383 with model ETS in generation 2 of 10\n",
            "Model Number: 384 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 385 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 386 with model Theta in generation 2 of 10\n",
            "Model Number: 387 with model FBProphet in generation 2 of 10\n",
            "Model Number: 388 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 389 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 390 with model FBProphet in generation 2 of 10\n",
            "Model Number: 391 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 392 with model Theta in generation 2 of 10\n",
            "Model Number: 393 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 393 in generation 2: DatepartRegression\n",
            "Model Number: 394 with model GLS in generation 2 of 10\n",
            "Model Number: 395 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 396 with model ETS in generation 2 of 10\n",
            "Model Number: 397 with model AverageValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "  warnings.warn(empty_warning_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 398 with model ARIMA in generation 2 of 10\n",
            "Model Number: 399 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 400 with model GLS in generation 2 of 10\n",
            "Model Number: 401 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 402 with model SeasonalNaive in generation 2 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 403 with model Theta in generation 2 of 10\n",
            "Model Number: 404 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 405 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 406 with model GLS in generation 2 of 10\n",
            "Model Number: 407 with model AverageValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 408 with model FBProphet in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 408 in generation 2: FBProphet\n",
            "Model Number: 409 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 410 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 411 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 412 with model AverageValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 413 with model GLM in generation 2 of 10\n",
            "Model Number: 414 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 415 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 416 with model GLS in generation 2 of 10\n",
            "Model Number: 417 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 418 with model GLM in generation 2 of 10\n",
            "Model Number: 419 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 420 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 421 with model WindowRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by KNeighborsRegressor.') in model 421 in generation 2: WindowRegression\n",
            "Model Number: 422 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 423 with model FBProphet in generation 2 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/thresholding.py:359: RuntimeWarning: invalid value encountered in divide\n",
            "  return abs(self.e_s - self.epsilon) / (self.mean_e_s + self.sd_e_s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Template Eval Error: IndexError('index 0 is out of bounds for axis 0 with size 0') in model 423 in generation 2: FBProphet\n",
            "Model Number: 424 with model GLS in generation 2 of 10\n",
            "Model Number: 425 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 426 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 427 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 427 in generation 2: DatepartRegression\n",
            "Model Number: 428 with model GLS in generation 2 of 10\n",
            "Model Number: 429 with model NVAR in generation 2 of 10\n",
            "Model Number: 430 with model NVAR in generation 2 of 10\n",
            "New Generation: 3 of 10\n",
            "Model Number: 431 with model GLS in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 431 in generation 3: GLS\n",
            "Model Number: 432 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 433 with model ARIMA in generation 3 of 10\n",
            "Model Number: 434 with model GLM in generation 3 of 10\n",
            "Model Number: 435 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 436 with model GLM in generation 3 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 436 in generation 3: GLM\n",
            "Model Number: 437 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 438 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 439 with model FBProphet in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 439 in generation 3: FBProphet\n",
            "Model Number: 440 with model Theta in generation 3 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1406: RuntimeWarning: invalid value encountered in log\n",
            "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 441 with model ETS in generation 3 of 10\n",
            "Model Number: 442 with model ETS in generation 3 of 10\n",
            "Model Number: 443 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 444 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 445 with model GLM in generation 3 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 445 in generation 3: GLM\n",
            "Model Number: 446 with model GLS in generation 3 of 10\n",
            "Model Number: 447 with model GLS in generation 3 of 10\n",
            "Model Number: 448 with model NVAR in generation 3 of 10\n",
            "Model Number: 449 with model GLS in generation 3 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:813: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return np.sum(resid / self.family.variance(mu)) / self.df_resid\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1650: RuntimeWarning: invalid value encountered in log\n",
            "  endog * np.log(endog / mu) + (mu - endog))\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 450 with model FBProphet in generation 3 of 10\n",
            "Model Number: 451 with model FBProphet in generation 3 of 10\n",
            "Model Number: 452 with model NVAR in generation 3 of 10\n",
            "Model Number: 453 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 454 with model Theta in generation 3 of 10\n",
            "Model Number: 455 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 456 with model ARIMA in generation 3 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/_loss/link.py:172: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.log(y_pred, out=out)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 457 with model AverageValueNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 457 in generation 3: AverageValueNaive\n",
            "Model Number: 458 with model ARIMA in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 458 in generation 3: ARIMA\n",
            "Model Number: 459 with model Theta in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 459 in generation 3: Theta\n",
            "Model Number: 460 with model ARDL in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 460 in generation 3: ARDL\n",
            "Model Number: 461 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 462 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 463 with model NVAR in generation 3 of 10\n",
            "Model Number: 464 with model NVAR in generation 3 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.974e+03, tolerance: 6.416e+01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 465 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 466 with model NVAR in generation 3 of 10\n",
            "Model Number: 467 with model ARIMA in generation 3 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
            "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 468 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 469 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 470 with model GLS in generation 3 of 10\n",
            "Model Number: 471 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 472 with model Theta in generation 3 of 10\n",
            "Model Number: 473 with model FBProphet in generation 3 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 474 with model GLS in generation 3 of 10\n",
            "Model Number: 475 with model DatepartRegression in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 475 in generation 3: DatepartRegression\n",
            "Model Number: 476 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 477 with model ARIMA in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 477 in generation 3: ARIMA\n",
            "Model Number: 478 with model NVAR in generation 3 of 10\n",
            "Model Number: 479 with model GLS in generation 3 of 10\n",
            "Model Number: 480 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 481 with model ETS in generation 3 of 10\n",
            "Model Number: 482 with model GLS in generation 3 of 10\n",
            "Model Number: 483 with model FBProphet in generation 3 of 10\n",
            "Model Number: 484 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 485 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 486 with model ARDL in generation 3 of 10\n",
            "Model Number: 487 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 488 with model UnobservedComponents in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 488 in generation 3: UnobservedComponents\n",
            "Model Number: 489 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 490 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 491 with model MultivariateRegression in generation 3 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 492 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 493 with model GLS in generation 3 of 10\n",
            "Model Number: 494 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 495 with model LastValueNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 495 in generation 3: LastValueNaive\n",
            "Model Number: 496 with model NVAR in generation 3 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 497 with model Theta in generation 3 of 10\n",
            "Model Number: 498 with model WindowRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 2 is required.') in model 498 in generation 3: WindowRegression\n",
            "Model Number: 499 with model NVAR in generation 3 of 10\n",
            "Model Number: 500 with model ETS in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 500 in generation 3: ETS\n",
            "Model Number: 501 with model GLS in generation 3 of 10\n",
            "Model Number: 502 with model ARIMA in generation 3 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
            "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 503 with model GLM in generation 3 of 10\n",
            "Model Number: 504 with model UnobservedComponents in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 504 in generation 3: UnobservedComponents\n",
            "Model Number: 505 with model ETS in generation 3 of 10\n",
            "Model Number: 506 with model ETS in generation 3 of 10\n",
            "Model Number: 507 with model UnobservedComponents in generation 3 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
            "  explained_variance_ratio_ = explained_variance_ / total_var\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 508 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 509 with model ETS in generation 3 of 10\n",
            "Model Number: 510 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 511 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 512 with model GLS in generation 3 of 10\n",
            "Model Number: 513 with model NVAR in generation 3 of 10\n",
            "Model Number: 514 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 515 with model Theta in generation 3 of 10\n",
            "Model Number: 516 with model ETS in generation 3 of 10\n",
            "Model Number: 517 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 518 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 519 with model NVAR in generation 3 of 10\n",
            "Model Number: 520 with model ARIMA in generation 3 of 10\n",
            "Model Number: 521 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 522 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 523 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 524 with model GLS in generation 3 of 10\n",
            "Model Number: 525 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 526 with model Theta in generation 3 of 10\n",
            "Model Number: 527 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 528 with model FBProphet in generation 3 of 10\n",
            "Model Number: 529 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 8s 8s/step - loss: 70.0088\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 69.9894\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 69.9616\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 69.9376\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 69.8944\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 69.8493\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 69.8003\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 69.7334\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 69.6578\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 69.5389\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 69.4005\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 69.2245\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 68.9842\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 68.6657\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 68.3101\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 67.8316\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 67.2148\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 66.5479\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 65.8706\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 65.2892\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 64.8175\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 64.3966\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 64.0569\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 63.8172\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 63.6323\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 63.5277\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 63.4491\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 63.3558\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 1s 522ms/step - loss: 63.2737\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 1s 535ms/step - loss: 63.2021\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 1s 544ms/step - loss: 63.1160\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 63.0337\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 62.9796\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 62.9050\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 62.8351\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 62.7645\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 62.7019\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 62.6348\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 62.5753\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 62.5108\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 62.4460\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 62.3844\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 62.3211\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 62.2642\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 62.2045\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 62.1423\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 62.0847\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 62.0239\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 61.9669\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 61.9070\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 530 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 531 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 532 with model UnobservedComponents in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 532 in generation 3: UnobservedComponents\n",
            "Model Number: 533 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 534 with model NVAR in generation 3 of 10\n",
            "Model Number: 535 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 536 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 537 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 538 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 539 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 540 with model UnobservedComponents in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 540 in generation 3: UnobservedComponents\n",
            "Model Number: 541 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 542 with model GLS in generation 3 of 10\n",
            "Model Number: 543 with model NVAR in generation 3 of 10\n",
            "Model Number: 544 with model Theta in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 544 in generation 3: Theta\n",
            "Model Number: 545 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 546 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 547 with model GLS in generation 3 of 10\n",
            "Model Number: 548 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 549 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 550 with model NVAR in generation 3 of 10\n",
            "Model Number: 551 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 552 with model SeasonalNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 552 in generation 3: SeasonalNaive\n",
            "Model Number: 553 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 554 with model NVAR in generation 3 of 10\n",
            "Model Number: 555 with model ARIMA in generation 3 of 10\n",
            "New Generation: 4 of 10\n",
            "Model Number: 556 with model UnobservedComponents in generation 4 of 10\n",
            "Template Eval Error: LinAlgError('Singular matrix') in model 556 in generation 4: UnobservedComponents\n",
            "Model Number: 557 with model Theta in generation 4 of 10\n",
            "Model Number: 558 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 559 with model GLS in generation 4 of 10\n",
            "Model Number: 560 with model Theta in generation 4 of 10\n",
            "Model Number: 561 with model ETS in generation 4 of 10\n",
            "Model Number: 562 with model Theta in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 562 in generation 4: Theta\n",
            "Model Number: 563 with model ARIMA in generation 4 of 10\n",
            "Model Number: 564 with model Theta in generation 4 of 10\n",
            "Model Number: 565 with model NVAR in generation 4 of 10\n",
            "Model Number: 566 with model NVAR in generation 4 of 10\n",
            "Model Number: 567 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 568 with model FBProphet in generation 4 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 569 with model ConstantNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 569 in generation 4: ConstantNaive\n",
            "Model Number: 570 with model AverageValueNaive in generation 4 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 571 with model Theta in generation 4 of 10\n",
            "Model Number: 572 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 573 with model ARIMA in generation 4 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
            "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 574 with model ETS in generation 4 of 10\n",
            "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "ETS failed on First with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
            "Model Number: 575 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 576 with model UnobservedComponents in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 576 in generation 4: UnobservedComponents\n",
            "Model Number: 577 with model DatepartRegression in generation 4 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 578 with model Theta in generation 4 of 10\n",
            "Model Number: 579 with model ARIMA in generation 4 of 10\n",
            "Model Number: 580 with model GLS in generation 4 of 10\n",
            "Model Number: 581 with model ETS in generation 4 of 10\n",
            "Model Number: 582 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 583 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 584 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 585 with model ARDL in generation 4 of 10\n",
            "Model Number: 586 with model FBProphet in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 586 in generation 4: FBProphet\n",
            "Model Number: 587 with model NVAR in generation 4 of 10\n",
            "Model Number: 588 with model NVAR in generation 4 of 10\n",
            "Model Number: 589 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 590 with model GLS in generation 4 of 10\n",
            "Model Number: 591 with model ETS in generation 4 of 10\n",
            "Model Number: 592 with model GLS in generation 4 of 10\n",
            "Model Number: 593 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 594 with model GLS in generation 4 of 10\n",
            "Model Number: 595 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 595 in generation 4: MultivariateRegression\n",
            "Model Number: 596 with model NVAR in generation 4 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2845: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2845: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 597 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 598 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 599 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 600 with model SeasonalNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 600 in generation 4: SeasonalNaive\n",
            "Model Number: 601 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 602 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 603 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 604 with model NVAR in generation 4 of 10\n",
            "Model Number: 605 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 606 with model GLS in generation 4 of 10\n",
            "Model Number: 607 with model SeasonalNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 607 in generation 4: SeasonalNaive\n",
            "Model Number: 608 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 609 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 610 with model NVAR in generation 4 of 10\n",
            "Model Number: 611 with model GLM in generation 4 of 10\n",
            "Model Number: 612 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 613 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 614 with model GLM in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 614 in generation 4: GLM\n",
            "Model Number: 615 with model NVAR in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 615 in generation 4: NVAR\n",
            "Model Number: 616 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 617 with model FBProphet in generation 4 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
            "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 618 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 619 with model ARIMA in generation 4 of 10\n",
            "Model Number: 620 with model Theta in generation 4 of 10\n",
            "Model Number: 621 with model ARIMA in generation 4 of 10\n",
            "Model Number: 622 with model NVAR in generation 4 of 10\n",
            "Model Number: 623 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 624 with model ETS in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 624 in generation 4: ETS\n",
            "Model Number: 625 with model LastValueNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 625 in generation 4: LastValueNaive\n",
            "Model Number: 626 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 627 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 628 with model WindowRegression in generation 4 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 628 in generation 4: WindowRegression\n",
            "Model Number: 629 with model NVAR in generation 4 of 10\n",
            "Model Number: 630 with model GLM in generation 4 of 10\n",
            "Model Number: 631 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 631 in generation 4: MultivariateRegression\n",
            "Model Number: 632 with model ETS in generation 4 of 10\n",
            "Model Number: 633 with model UnobservedComponents in generation 4 of 10\n",
            "Template Eval Error: LinAlgError('Singular matrix') in model 633 in generation 4: UnobservedComponents\n",
            "Model Number: 634 with model DatepartRegression in generation 4 of 10\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 7s 7s/step - loss: 165.0805\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 165.0495\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 165.0169\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 164.9799\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 164.9351\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 164.8818\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 164.8209\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 164.7470\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 164.6441\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 164.5275\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 164.3836\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 164.2027\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 163.9478\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 163.6403\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 163.2825\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 162.7523\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 162.0437\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 161.2318\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 160.2922\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 1s 515ms/step - loss: 159.5984\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 159.0102\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 158.3028\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 157.7400\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 157.3324\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 156.9386\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 156.7194\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 156.5591\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 156.4589\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 156.3336\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 156.2511\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 156.1026\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 156.0204\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 155.9399\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 155.8514\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 155.7677\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 155.6868\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 155.6222\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 155.5555\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 155.4879\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 155.4202\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 155.3507\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 155.2817\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 155.2168\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 155.1625\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 155.0918\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 155.0340\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 154.9680\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 154.9038\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 154.8490\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 154.7874\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 635 with model DatepartRegression in generation 4 of 10\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 6s 6s/step - loss: 70.0138\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 69.9923\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 69.9671\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 69.9421\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 69.9026\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 69.8708\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 69.8217\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 69.7561\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 69.6848\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 69.5901\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 69.4635\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 69.2835\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 69.1165\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 68.8516\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 68.5580\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 68.0731\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 67.5189\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 66.9045\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 66.2158\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 65.5235\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 64.9121\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 64.4318\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 63.9875\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 63.6598\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 63.3513\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 63.1656\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 63.0311\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 62.9040\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 62.8105\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 62.7448\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 62.6148\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 62.5277\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 62.4688\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 62.3840\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 62.3102\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 62.2240\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 62.1695\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 62.0974\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 1s 593ms/step - loss: 62.0445\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 1s 550ms/step - loss: 61.9425\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 1s 537ms/step - loss: 61.8902\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 61.8094\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 61.7496\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 61.6856\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 61.6200\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 61.5542\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 61.4901\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 61.4302\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 61.3722\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 61.3095\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 636 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 637 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 638 with model DatepartRegression in generation 4 of 10\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 6s 6s/step - loss: 93.1379\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 93.1227\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 93.1072\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 93.0890\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 93.0653\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 93.0374\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 93.0133\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 92.9769\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 92.9331\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 92.8709\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 92.8063\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 92.7139\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 92.5895\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 92.4327\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 92.2370\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 92.0155\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 91.7088\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 91.3592\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 90.8798\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 90.3996\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 90.0145\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 89.6621\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 89.2817\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 89.0611\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 88.8231\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 88.7116\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 88.6405\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 1s 510ms/step - loss: 88.5566\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 88.5108\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 88.4221\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 88.3514\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 88.2998\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 88.2528\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 88.1911\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 88.1494\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 88.0906\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 88.0387\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 87.9932\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 87.9499\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 87.8981\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 87.8580\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 87.8079\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 87.7649\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 87.7253\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 87.6779\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 87.6346\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 87.5933\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 87.5495\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 87.5123\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 87.4600\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 639 with model GLS in generation 4 of 10\n",
            "Model Number: 640 with model ETS in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 640 in generation 4: ETS\n",
            "Model Number: 641 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 642 with model LastValueNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 642 in generation 4: LastValueNaive\n",
            "Model Number: 643 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 644 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 645 with model ETS in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 645 in generation 4: ETS\n",
            "Model Number: 646 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 647 with model ConstantNaive in generation 4 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 648 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 649 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 650 with model Theta in generation 4 of 10\n",
            "Model Number: 651 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 652 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 653 with model Theta in generation 4 of 10\n",
            "Model Number: 654 with model Theta in generation 4 of 10\n",
            "Model Number: 655 with model WindowRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nRegressorChain does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 655 in generation 4: WindowRegression\n",
            "Model Number: 656 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 657 with model FBProphet in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 657 in generation 4: FBProphet\n",
            "Model Number: 658 with model GLS in generation 4 of 10\n",
            "Model Number: 659 with model NVAR in generation 4 of 10\n",
            "Model Number: 660 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 661 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 662 with model GLS in generation 4 of 10\n",
            "Model Number: 663 with model AverageValueNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 663 in generation 4: AverageValueNaive\n",
            "Model Number: 664 with model LastValueNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 664 in generation 4: LastValueNaive\n",
            "Model Number: 665 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 666 with model SeasonalNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 666 in generation 4: SeasonalNaive\n",
            "Model Number: 667 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 668 with model NVAR in generation 4 of 10\n",
            "Model Number: 669 with model FBProphet in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 669 in generation 4: FBProphet\n",
            "Model Number: 670 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 671 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 672 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 673 with model UnobservedComponents in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 673 in generation 4: UnobservedComponents\n",
            "Model Number: 674 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 675 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 676 with model UnobservedComponents in generation 4 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
            "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 677 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 678 with model FBProphet in generation 4 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 679 with model LastValueNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 679 in generation 4: LastValueNaive\n",
            "Model Number: 680 with model GLS in generation 4 of 10\n",
            "New Generation: 5 of 10\n",
            "Model Number: 681 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 682 with model FBProphet in generation 5 of 10\n",
            "Model Number: 683 with model FBProphet in generation 5 of 10\n",
            "Model Number: 684 with model LastValueNaive in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 684 in generation 5: LastValueNaive\n",
            "Model Number: 685 with model FBProphet in generation 5 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 686 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 687 with model Theta in generation 5 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (5). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 688 with model NVAR in generation 5 of 10\n",
            "Model Number: 689 with model Theta in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 689 in generation 5: Theta\n",
            "Model Number: 690 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 691 with model GLS in generation 5 of 10\n",
            "Model Number: 692 with model GLS in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 692 in generation 5: GLS\n",
            "Model Number: 693 with model UnobservedComponents in generation 5 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 694 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 695 with model GLS in generation 5 of 10\n",
            "Model Number: 696 with model Theta in generation 5 of 10\n",
            "Model Number: 697 with model Theta in generation 5 of 10\n",
            "Model Number: 698 with model NVAR in generation 5 of 10\n",
            "Model Number: 699 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 700 with model ETS in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 700 in generation 5: ETS\n",
            "Model Number: 701 with model GLM in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 701 in generation 5: GLM\n",
            "Model Number: 702 with model AverageValueNaive in generation 5 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 703 with model NVAR in generation 5 of 10\n",
            "Model Number: 704 with model NVAR in generation 5 of 10\n",
            "Model Number: 705 with model GLM in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 705 in generation 5: GLM\n",
            "Model Number: 706 with model FBProphet in generation 5 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 707 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 708 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 709 with model GLM in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 709 in generation 5: GLM\n",
            "Model Number: 710 with model ARIMA in generation 5 of 10\n",
            "Model Number: 711 with model ARIMA in generation 5 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 712 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 713 with model FBProphet in generation 5 of 10\n",
            "Model Number: 714 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 715 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 716 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 717 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 718 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 719 with model ETS in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 719 in generation 5: ETS\n",
            "Model Number: 720 with model Theta in generation 5 of 10\n",
            "Model Number: 721 with model NVAR in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 721 in generation 5: NVAR\n",
            "Model Number: 722 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 723 with model NVAR in generation 5 of 10\n",
            "Model Number: 724 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 725 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 726 with model ARIMA in generation 5 of 10\n",
            "Model Number: 727 with model FBProphet in generation 5 of 10\n",
            "Model Number: 728 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 729 with model GLS in generation 5 of 10\n",
            "Model Number: 730 with model FBProphet in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 730 in generation 5: FBProphet\n",
            "Model Number: 731 with model GLS in generation 5 of 10\n",
            "Model Number: 732 with model NVAR in generation 5 of 10\n",
            "Model Number: 733 with model GLS in generation 5 of 10\n",
            "Model Number: 734 with model ConstantNaive in generation 5 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 735 with model LastValueNaive in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 735 in generation 5: LastValueNaive\n",
            "Model Number: 736 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 737 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 738 with model ETS in generation 5 of 10\n",
            "Model Number: 739 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 740 with model DatepartRegression in generation 5 of 10\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 7s 7s/step - loss: 1.0181\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 1.0173\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 1.0174\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 1.0169\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 1.0149\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 1.0144\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 1.0152\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 1.0142\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 1.0159\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 1.0154\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 1.0147\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 1.0126\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 1.0140\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 1.0137\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 1.0141\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 1.0123\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 1.0120\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 1.0110\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 1.0093\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 1.0098\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 1.0087\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 1.0124\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 1.0051\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 1.0066\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 1.0080\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 1.0057\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 1.0055\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 1.0013\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 417ms/step - loss: 1.0034\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 1.0031\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 1.0019\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.9974\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.9927\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.9917\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.9904\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.9880\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.9943\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.9892\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.9756\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.9698\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 0.9731\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.9696\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.9762\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.9605\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.9448\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.9583\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.9402\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.9448\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.9377\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.9476\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 741 with model LastValueNaive in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 741 in generation 5: LastValueNaive\n",
            "Model Number: 742 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 743 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 744 with model GLM in generation 5 of 10\n",
            "Model Number: 745 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 746 with model ConstantNaive in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'mean', 'transformations': {'0': 'KalmanSmoothing', '1': 'AlignLastValue', '2': 'EWMAFilter', '3': 'Detrend', '4': 'SeasonalDifference'}, 'transformation_params': {'0': {'model_name': 'randomly generated', 'state_transition': [[1, 0, 0, 0], [0, 1, 0, 0], [-1, 0, 0, 0], [1, 0, 0, 0]], 'process_noise': [[0.002, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0]], 'observation_model': [[1, 1, 0, 0]], 'observation_noise': 1.0, 'em_iter': 10}, '1': {'rows': 4, 'lag': 28, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '2': {'span': 3}, '3': {'model': 'GLS', 'phi': 1, 'window': None, 'transform_dict': None}, '4': {'lag_1': 4, 'method': 'Median'}}}. fail_on_forecast_nan=True\") in model 746 in generation 5: ConstantNaive\n",
            "Model Number: 747 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 748 with model ETS in generation 5 of 10\n",
            "Model Number: 749 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 750 with model NVAR in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 750 in generation 5: NVAR\n",
            "Model Number: 751 with model UnobservedComponents in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 751 in generation 5: UnobservedComponents\n",
            "Model Number: 752 with model DatepartRegression in generation 5 of 10\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 6s 6s/step - loss: 74.3639\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 74.3306\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 74.2913\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 74.2509\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 74.1987\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 74.1397\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 74.0737\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 73.9890\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 73.8763\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 73.7467\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 1s 522ms/step - loss: 73.5723\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 1s 550ms/step - loss: 73.3774\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 1s 517ms/step - loss: 73.1148\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 72.7535\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 72.3155\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 71.7196\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 70.9335\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 70.0108\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 68.9247\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 67.7905\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 66.8792\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 66.0895\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 65.3791\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 64.9055\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 64.5132\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 64.2410\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 64.0795\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 63.9104\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 63.7733\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 63.6466\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 63.4961\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 63.3722\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 63.2766\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 63.1547\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 63.0546\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 62.9391\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 62.8428\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 62.7348\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 62.6421\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 62.5402\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 62.4444\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 62.3412\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 62.2460\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 62.1578\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 62.0585\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 61.9661\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 1s 551ms/step - loss: 61.8685\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 1s 505ms/step - loss: 61.7744\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 61.6840\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 61.5906\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Model Number: 753 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 754 with model ETS in generation 5 of 10\n",
            "Model Number: 755 with model ETS in generation 5 of 10\n",
            "Model Number: 756 with model ARDL in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 756 in generation 5: ARDL\n",
            "Model Number: 757 with model ETS in generation 5 of 10\n",
            "Model Number: 758 with model ARDL in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (10) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (9).') exog train             year  month  day  weekday\\nperiod_end                           \\n2020-05-31  2020      5   31        6\\n2020-06-30  2020      6   30        1\\n2020-07-31  2020      7   31        4\\n2020-08-31  2020      8   31        0\\n2020-09-30  2020      9   30        2\\n2020-10-31  2020     10   31        5\\n2020-11-30  2020     11   30        0\\n2020-12-31  2020     12   31        3\\n2021-01-31  2021      1   31        6\\n2021-02-28  2021      2   28        6\\n2021-03-31  2021      3   31        2 and predict             year  month  day  weekday\\n2021-04-30  2021      4   30        4\\n2021-05-31  2021      5   31        0\\n2021-06-30  2021      6   30        2\\n2021-07-31  2021      7   31        5\") in model 758 in generation 5: ARDL\n",
            "Model Number: 759 with model GLS in generation 5 of 10\n",
            "Model Number: 760 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 761 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 762 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 763 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 764 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 765 with model NVAR in generation 5 of 10\n",
            "Model Number: 766 with model ConstantNaive in generation 5 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 767 with model NVAR in generation 5 of 10\n",
            "Model Number: 768 with model ETS in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 768 in generation 5: ETS\n",
            "Model Number: 769 with model GLS in generation 5 of 10\n",
            "Model Number: 770 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 771 with model ARIMA in generation 5 of 10\n",
            "Model Number: 772 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 773 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 774 with model GLS in generation 5 of 10\n",
            "Model Number: 775 with model NVAR in generation 5 of 10\n",
            "Model Number: 776 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 777 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 778 with model GLM in generation 5 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 778 in generation 5: GLM\n",
            "Model Number: 779 with model Theta in generation 5 of 10\n",
            "Model Number: 780 with model GLM in generation 5 of 10"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1406: RuntimeWarning: invalid value encountered in log\n",
            "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "New Generation: 6 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1257: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 781 with model ARIMA in generation 6 of 10\n",
            "Model Number: 782 with model ARIMA in generation 6 of 10\n",
            "Model Number: 783 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 784 with model FBProphet in generation 6 of 10\n",
            "Model Number: 785 with model GLS in generation 6 of 10\n",
            "Model Number: 786 with model Theta in generation 6 of 10\n",
            "Model Number: 787 with model DatepartRegression in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 787 in generation 6: DatepartRegression\n",
            "Model Number: 788 with model GLM in generation 6 of 10\n",
            "Model Number: 789 with model GLS in generation 6 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 789 in generation 6: GLS\n",
            "Model Number: 790 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 791 with model ARDL in generation 6 of 10\n",
            "Model Number: 792 with model UnobservedComponents in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 792 in generation 6: UnobservedComponents\n",
            "Model Number: 793 with model NVAR in generation 6 of 10\n",
            "Model Number: 794 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 795 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 796 with model ConstantNaive in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 796 in generation 6: ConstantNaive\n",
            "Model Number: 797 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 798 with model GLM in generation 6 of 10\n",
            "Model Number: 799 with model ETS in generation 6 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on First with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 800 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 801 with model GLS in generation 6 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 802 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 803 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 804 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 805 with model LastValueNaive in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 805 in generation 6: LastValueNaive\n",
            "Model Number: 806 with model Theta in generation 6 of 10\n",
            "Model Number: 807 with model ETS in generation 6 of 10\n",
            "Model Number: 808 with model NVAR in generation 6 of 10\n",
            "Model Number: 809 with model GLS in generation 6 of 10\n",
            "Model Number: 810 with model ARIMA in generation 6 of 10\n",
            "Model Number: 811 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 812 with model Theta in generation 6 of 10\n",
            "Model Number: 813 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 814 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 815 with model ConstantNaive in generation 6 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 816 with model ETS in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 816 in generation 6: ETS\n",
            "Model Number: 817 with model ETS in generation 6 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on First with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 818 with model DatepartRegression in generation 6 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 819 with model LastValueNaive in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 819 in generation 6: LastValueNaive\n",
            "Model Number: 820 with model GLS in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 820 in generation 6: GLS\n",
            "Model Number: 821 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 822 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 823 with model FBProphet in generation 6 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 824 with model Theta in generation 6 of 10\n",
            "Template Eval Error: ValueError('x must have 2 complete cycles requires 24 observations. x only has 11 observation(s)') in model 824 in generation 6: Theta\n",
            "Model Number: 825 with model Theta in generation 6 of 10\n",
            "Model Number: 826 with model GLS in generation 6 of 10\n",
            "Model Number: 827 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 828 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 829 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 830 with model NVAR in generation 6 of 10\n",
            "Model Number: 831 with model ETS in generation 6 of 10\n",
            "Model Number: 832 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 833 with model NVAR in generation 6 of 10\n",
            "Model Number: 834 with model SeasonalNaive in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'fake_date', 'transformations': {'0': 'AlignLastValue', '1': 'DifferencedTransformer', '2': 'EWMAFilter', '3': 'QuantileTransformer', '4': 'RobustScaler'}, 'transformation_params': {'0': {'rows': 4, 'lag': 28, 'method': 'additive', 'strength': 0.7, 'first_value_only': False}, '1': {}, '2': {'span': 3}, '3': {'output_distribution': 'normal', 'n_quantiles': 3}, '4': {}}}. fail_on_forecast_nan=True\") in model 834 in generation 6: SeasonalNaive\n",
            "Model Number: 835 with model FBProphet in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 835 in generation 6: FBProphet\n",
            "Model Number: 836 with model ETS in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 836 in generation 6: ETS\n",
            "Model Number: 837 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 838 with model GLS in generation 6 of 10\n",
            "Model Number: 839 with model ARDL in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 839 in generation 6: ARDL\n",
            "Model Number: 840 with model ETS in generation 6 of 10\n",
            "Model Number: 841 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 842 with model NVAR in generation 6 of 10\n",
            "Model Number: 843 with model Theta in generation 6 of 10\n",
            "Model Number: 844 with model FBProphet in generation 6 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 845 with model SeasonalNaive in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 845 in generation 6: SeasonalNaive\n",
            "Model Number: 846 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 847 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 848 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 849 with model FBProphet in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 849 in generation 6: FBProphet\n",
            "Model Number: 850 with model Theta in generation 6 of 10\n",
            "Model Number: 851 with model Theta in generation 6 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
            "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 852 with model ARIMA in generation 6 of 10\n",
            "Model Number: 853 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 854 with model ETS in generation 6 of 10\n",
            "Model Number: 855 with model NVAR in generation 6 of 10\n",
            "Model Number: 856 with model WindowRegression in generation 6 of 10\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Model Number: 857 with model WindowRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by ExtraTreesRegressor.') in model 857 in generation 6: WindowRegression\n",
            "Model Number: 858 with model ETS in generation 6 of 10\n",
            "Model Number: 859 with model GLM in generation 6 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 859 in generation 6: GLM\n",
            "Model Number: 860 with model ARIMA in generation 6 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:813: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  return np.sum(resid / self.family.variance(mu)) / self.df_resid\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 861 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 862 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 863 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 864 with model DatepartRegression in generation 6 of 10\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 7s 7s/step - loss: 214.2116\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 454ms/step - loss: 214.1755\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 214.1343\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 214.0932\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 214.0407\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 213.9715\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 213.8994\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 213.7983\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 213.6821\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 213.5281\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 213.3383\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 213.1137\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 212.7891\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 212.3724\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 211.8772\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 211.1991\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 210.2659\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 209.2730\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 208.0892\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 206.9440\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 205.9936\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 205.2436\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 204.5296\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 204.1420\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 203.9031\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 203.6921\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 203.5012\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 203.3310\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 203.1696\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 203.0262\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 202.8730\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 202.7341\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 1s 544ms/step - loss: 202.6133\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 202.4855\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 1s 540ms/step - loss: 202.3647\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 202.2410\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 202.1218\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 201.9987\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 201.8921\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 201.7831\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 201.6756\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 201.5450\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 201.4465\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 201.3362\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 201.2291\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 201.1186\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 201.0195\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 200.9091\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 200.8168\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 200.7030\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 865 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 866 with model NVAR in generation 6 of 10\n",
            "Model Number: 867 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 868 with model NVAR in generation 6 of 10\n",
            "Model Number: 869 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 870 with model Theta in generation 6 of 10\n",
            "Model Number: 871 with model ETS in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 871 in generation 6: ETS\n",
            "Model Number: 872 with model ARIMA in generation 6 of 10\n",
            "Model Number: 873 with model NVAR in generation 6 of 10\n",
            "Model Number: 874 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 875 with model ARDL in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 875 in generation 6: ARDL\n",
            "Model Number: 876 with model Theta in generation 6 of 10\n",
            "Model Number: 877 with model WindowRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 877 in generation 6: WindowRegression\n",
            "Model Number: 878 with model FBProphet in generation 6 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 879 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 880 with model NVAR in generation 6 of 10\n",
            "New Generation: 7 of 10\n",
            "Model Number: 881 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 882 with model Theta in generation 7 of 10\n",
            "Model Number: 883 with model NVAR in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 883 in generation 7: NVAR\n",
            "Model Number: 884 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 885 with model GLS in generation 7 of 10\n",
            "Model Number: 886 with model GLS in generation 7 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/thresholding.py:359: RuntimeWarning: invalid value encountered in divide\n",
            "  return abs(self.e_s - self.epsilon) / (self.mean_e_s + self.sd_e_s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 887 with model ARIMA in generation 7 of 10\n",
            "Model Number: 888 with model FBProphet in generation 7 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 889 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 890 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 891 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 892 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 893 with model Theta in generation 7 of 10\n",
            "Model Number: 894 with model NVAR in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 894 in generation 7: NVAR\n",
            "Model Number: 895 with model GLS in generation 7 of 10\n",
            "Model Number: 896 with model WindowRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by PoissonRegressor.') in model 896 in generation 7: WindowRegression\n",
            "Model Number: 897 with model NVAR in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 897 in generation 7: NVAR\n",
            "Model Number: 898 with model GLS in generation 7 of 10\n",
            "Model Number: 899 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 900 with model GLS in generation 7 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 901 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 902 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 903 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError('Some value(s) of y are negative which is not allowed for Poisson regression.') in model 903 in generation 7: MultivariateRegression\n",
            "Model Number: 904 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 905 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 906 with model UnobservedComponents in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 906 in generation 7: UnobservedComponents\n",
            "Model Number: 907 with model WindowRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by PoissonRegressor.') in model 907 in generation 7: WindowRegression\n",
            "Model Number: 908 with model ETS in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 908 in generation 7: ETS\n",
            "Model Number: 909 with model ETS in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 909 in generation 7: ETS\n",
            "Model Number: 910 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 911 with model NVAR in generation 7 of 10\n",
            "Model Number: 912 with model ARIMA in generation 7 of 10\n",
            "Model Number: 913 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError('Need at least 3 dates to infer frequency') in model 913 in generation 7: MultivariateRegression\n",
            "Model Number: 914 with model SeasonalNaive in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 914 in generation 7: SeasonalNaive\n",
            "Model Number: 915 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 916 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 917 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 918 with model NVAR in generation 7 of 10\n",
            "Model Number: 919 with model NVAR in generation 7 of 10\n",
            "Model Number: 920 with model GLS in generation 7 of 10\n",
            "Model Number: 921 with model FBProphet in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 921 in generation 7: FBProphet\n",
            "Model Number: 922 with model FBProphet in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 922 in generation 7: FBProphet\n",
            "Model Number: 923 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 924 with model Theta in generation 7 of 10\n",
            "Model Number: 925 with model GLM in generation 7 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 925 in generation 7: GLM\n",
            "Model Number: 926 with model FBProphet in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 926 in generation 7: FBProphet\n",
            "Model Number: 927 with model DatepartRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'ClipOutliers', '1': 'SeasonalDifference', '2': 'cffilter', '3': 'AlignLastValue'}, 'transformation_params': {'0': {'method': 'clip', 'std_threshold': 3, 'fillna': None}, '1': {'lag_1': 11, 'method': 'Median'}, '2': {}, '3': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 0.9, 'first_value_only': False}}}. fail_on_forecast_nan=True\") in model 927 in generation 7: DatepartRegression\n",
            "Model Number: 928 with model NVAR in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 928 in generation 7: NVAR\n",
            "Model Number: 929 with model AverageValueNaive in generation 7 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:445: RuntimeWarning: divide by zero encountered in divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:143: RuntimeWarning: divide by zero encountered in divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 930 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 931 with model ARIMA in generation 7 of 10\n",
            "Model Number: 932 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 933 with model ETS in generation 7 of 10\n",
            "Model Number: 934 with model DatepartRegression in generation 7 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 935 with model Theta in generation 7 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 936 with model Theta in generation 7 of 10\n",
            "Model Number: 937 with model NVAR in generation 7 of 10\n",
            "Model Number: 938 with model GLM in generation 7 of 10\n",
            "Model Number: 939 with model FBProphet in generation 7 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 940 with model SeasonalNaive in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 940 in generation 7: SeasonalNaive\n",
            "Model Number: 941 with model ARIMA in generation 7 of 10\n",
            "Model Number: 942 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 943 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 944 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 944 in generation 7: MultivariateRegression\n",
            "Model Number: 945 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 946 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 947 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 948 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 949 with model FBProphet in generation 7 of 10\n",
            "Model Number: 950 with model FBProphet in generation 7 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 951 with model FBProphet in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 951 in generation 7: FBProphet\n",
            "Model Number: 952 with model WindowRegression in generation 7 of 10\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
            "Template Eval Error: LightGBMError('[gamma]: at least one target label is negative') in model 952 in generation 7: WindowRegression\n",
            "Model Number: 953 with model SeasonalNaive in generation 7 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 954 with model ARDL in generation 7 of 10\n",
            "Model Number: 955 with model Theta in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 955 in generation 7: Theta\n",
            "Model Number: 956 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 957 with model GLM in generation 7 of 10\n",
            "Model Number: 958 with model GLS in generation 7 of 10\n",
            "Model Number: 959 with model ARDL in generation 7 of 10\n",
            "Model Number: 960 with model Theta in generation 7 of 10\n",
            "Model Number: 961 with model FBProphet in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 961 in generation 7: FBProphet\n",
            "Model Number: 962 with model Theta in generation 7 of 10\n",
            "Model Number: 963 with model GLS in generation 7 of 10\n",
            "Model Number: 964 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 965 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 965 in generation 7: MultivariateRegression\n",
            "Model Number: 966 with model Theta in generation 7 of 10\n",
            "Model Number: 967 with model Theta in generation 7 of 10\n",
            "Model Number: 968 with model GLM in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 968 in generation 7: GLM\n",
            "Model Number: 969 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 970 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 971 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 972 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 973 with model Theta in generation 7 of 10\n",
            "Model Number: 974 with model ARDL in generation 7 of 10\n",
            "Model Number: 975 with model ETS in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 975 in generation 7: ETS\n",
            "Model Number: 976 with model GLS in generation 7 of 10\n",
            "Model Number: 977 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 978 with model UnobservedComponents in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 978 in generation 7: UnobservedComponents\n",
            "Model Number: 979 with model ARIMA in generation 7 of 10\n",
            "Model Number: 980 with model ConstantNaive in generation 7 of 10\n",
            "New Generation: 8 of 10\n",
            "Model Number: 981 with model AverageValueNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 981 in generation 8: AverageValueNaive\n",
            "Model Number: 982 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 983 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 984 with model ETS in generation 8 of 10\n",
            "Model Number: 985 with model ETS in generation 8 of 10\n",
            "Model Number: 986 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 987 with model GLM in generation 8 of 10\n",
            "Model Number: 988 with model NVAR in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 988 in generation 8: NVAR\n",
            "Model Number: 989 with model GLM in generation 8 of 10\n",
            "Model Number: 990 with model SeasonalNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 990 in generation 8: SeasonalNaive\n",
            "Model Number: 991 with model FBProphet in generation 8 of 10\n",
            "Model Number: 992 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 993 with model Theta in generation 8 of 10\n",
            "Model Number: 994 with model FBProphet in generation 8 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 995 with model Theta in generation 8 of 10\n",
            "Model Number: 996 with model GLS in generation 8 of 10\n",
            "Model Number: 997 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 998 with model FBProphet in generation 8 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 999 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1000 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1000 in generation 8: DatepartRegression\n",
            "Model Number: 1001 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 1002 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 1002 in generation 8: DatepartRegression\n",
            "Model Number: 1003 with model FBProphet in generation 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1004 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1005 with model FBProphet in generation 8 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1006 with model LastValueNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1006 in generation 8: LastValueNaive\n",
            "Model Number: 1007 with model ARIMA in generation 8 of 10\n",
            "Model Number: 1008 with model ARIMA in generation 8 of 10\n",
            "Model Number: 1009 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1010 with model ETS in generation 8 of 10\n",
            "Model Number: 1011 with model ARDL in generation 8 of 10\n",
            "Model Number: 1012 with model GLS in generation 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1013 with model ETS in generation 8 of 10\n",
            "Model Number: 1014 with model DatepartRegression in generation 8 of 10\n",
            "Model Number: 1015 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 1016 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1017 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1018 with model Theta in generation 8 of 10\n",
            "Model Number: 1019 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 1020 with model GLS in generation 8 of 10\n",
            "Model Number: 1021 with model DatepartRegression in generation 8 of 10\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 6s 6s/step - loss: 59.4988\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 59.4935\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 59.4927\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 59.4885\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 59.4855\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 59.4806\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 59.4782\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 59.4756\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 59.4632\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 1s 545ms/step - loss: 59.4603\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 1s 541ms/step - loss: 59.4403\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 59.4477\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 59.4203\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 59.4075\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 59.3912\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 59.3674\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 59.3473\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 59.3214\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 59.2938\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 59.1989\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 59.1010\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 59.0989\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 58.9422\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 58.8762\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 58.9458\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 58.9138\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 58.8071\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 58.8803\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 58.9037\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 58.8843\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 58.9494\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 58.8631\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 58.9085\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 58.8273\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 58.7962\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 58.9366\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 58.9696\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 59.0011\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 58.8555\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 58.8251\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 58.8243\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 58.8854\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 58.8954\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 1s 563ms/step - loss: 58.8815\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 58.9467\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 58.8897\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 58.9222\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 58.9167\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 58.8658\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 58.8339\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 1022 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1023 with model UnobservedComponents in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1023 in generation 8: UnobservedComponents\n",
            "Model Number: 1024 with model GLS in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 1024 in generation 8: GLS\n",
            "Model Number: 1025 with model FBProphet in generation 8 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1026 with model Theta in generation 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1027 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1028 with model NVAR in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1028 in generation 8: NVAR\n",
            "Model Number: 1029 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1030 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1031 with model Theta in generation 8 of 10\n",
            "Model Number: 1032 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1033 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 1034 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 1035 with model NVAR in generation 8 of 10\n",
            "Model Number: 1036 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1036 in generation 8: DatepartRegression\n",
            "Model Number: 1037 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1038 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1039 with model NVAR in generation 8 of 10\n",
            "Model Number: 1040 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 1041 with model WindowRegression in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 1041 in generation 8: WindowRegression\n",
            "Model Number: 1042 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 1043 with model ARIMA in generation 8 of 10\n",
            "Model Number: 1044 with model AverageValueNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1044 in generation 8: AverageValueNaive\n",
            "Model Number: 1045 with model GLM in generation 8 of 10\n",
            "Model Number: 1046 with model FBProphet in generation 8 of 10\n",
            "Model Number: 1047 with model GLS in generation 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1048 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1049 with model GLS in generation 8 of 10\n",
            "Model Number: 1050 with model NVAR in generation 8 of 10\n",
            "Model Number: 1051 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 1052 with model ARDL in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('integer orders must be at least 1 when causal is True.') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0\\n2020-12-31             0.0\\n2021-01-31             0.0\\n2021-02-28             0.0\\n2021-03-31             0.0 and predict             HolidayFlag_US\\n2021-04-30             0.0\\n2021-05-31             1.0\\n2021-06-30             0.0\\n2021-07-31             0.0\") in model 1052 in generation 8: ARDL\n",
            "Model Number: 1053 with model GLS in generation 8 of 10\n",
            "Model Number: 1054 with model FBProphet in generation 8 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1055 with model NVAR in generation 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1056 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1057 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 1058 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 1059 with model AverageValueNaive in generation 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1060 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1061 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1062 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 1063 with model NVAR in generation 8 of 10\n",
            "Model Number: 1064 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1065 with model Theta in generation 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [06:28:02] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"predictor\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1066 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1067 with model GLM in generation 8 of 10\n",
            "Model Number: 1068 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1069 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 1070 with model ETS in generation 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1071 with model NVAR in generation 8 of 10\n",
            "Model Number: 1072 with model FBProphet in generation 8 of 10\n",
            "Model Number: 1073 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1074 with model GLM in generation 8 of 10\n",
            "Model Number: 1075 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1076 with model ARDL in generation 8 of 10\n",
            "Model Number: 1077 with model UnobservedComponents in generation 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1077 in generation 8: UnobservedComponents\n",
            "Model Number: 1078 with model ETS in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1078 in generation 8: ETS\n",
            "Model Number: 1079 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1079 in generation 8: DatepartRegression\n",
            "Model Number: 1080 with model Theta in generation 8 of 10\n",
            "New Generation: 9 of 10\n",
            "Model Number: 1081 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1081 in generation 9: DatepartRegression\n",
            "Model Number: 1082 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1083 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1084 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1085 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1086 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1087 with model SeasonalNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 1087 in generation 9: SeasonalNaive\n",
            "Model Number: 1088 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1089 with model Theta in generation 9 of 10\n",
            "Model Number: 1090 with model FBProphet in generation 9 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1091 with model SeasonalNaive in generation 9 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1092 with model FBProphet in generation 9 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1093 with model SeasonalNaive in generation 9 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1094 with model WindowRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by AdaBoostRegressor.') in model 1094 in generation 9: WindowRegression\n",
            "Model Number: 1095 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1096 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1097 with model FBProphet in generation 9 of 10\n",
            "Model Number: 1098 with model NVAR in generation 9 of 10\n",
            "Model Number: 1099 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1100 with model NVAR in generation 9 of 10\n",
            "Model Number: 1101 with model Theta in generation 9 of 10\n",
            "Model Number: 1102 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1103 with model GLM in generation 9 of 10\n",
            "Model Number: 1104 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1105 with model ETS in generation 9 of 10\n",
            "Model Number: 1106 with model NVAR in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1106 in generation 9: NVAR\n",
            "Model Number: 1107 with model GLS in generation 9 of 10\n",
            "Model Number: 1108 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1109 with model FBProphet in generation 9 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1110 with model FBProphet in generation 9 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1111 with model Theta in generation 9 of 10\n",
            "Model Number: 1112 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1113 with model GLS in generation 9 of 10\n",
            "Model Number: 1114 with model WindowRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1114 in generation 9: WindowRegression\n",
            "Model Number: 1115 with model Theta in generation 9 of 10\n",
            "Model Number: 1116 with model ETS in generation 9 of 10\n",
            "Model Number: 1117 with model FBProphet in generation 9 of 10\n",
            "Model Number: 1118 with model FBProphet in generation 9 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1119 with model ConstantNaive in generation 9 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1120 with model NVAR in generation 9 of 10\n",
            "Model Number: 1121 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 1121 in generation 9: DatepartRegression\n",
            "Model Number: 1122 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1123 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1124 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "  warnings.warn(empty_warning_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1125 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1126 with model NVAR in generation 9 of 10\n",
            "Model Number: 1127 with model Theta in generation 9 of 10\n",
            "Model Number: 1128 with model NVAR in generation 9 of 10\n",
            "Model Number: 1129 with model GLS in generation 9 of 10\n",
            "Model Number: 1130 with model MultivariateRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 1130 in generation 9: MultivariateRegression\n",
            "Model Number: 1131 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1132 with model NVAR in generation 9 of 10\n",
            "Model Number: 1133 with model WindowRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by PoissonRegressor.') in model 1133 in generation 9: WindowRegression\n",
            "Model Number: 1134 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1135 with model FBProphet in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1135 in generation 9: FBProphet\n",
            "Model Number: 1136 with model NVAR in generation 9 of 10\n",
            "Model Number: 1137 with model ConstantNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 1137 in generation 9: ConstantNaive\n",
            "Model Number: 1138 with model Theta in generation 9 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1139 with model WindowRegression in generation 9 of 10\n",
            "Template Eval Error: XGBoostError('[06:28:13] /workspace/src/data/iterative_dmatrix.cc:202: Check failed: n_features >= 1 (0 vs. 1) : Data must has at least 1 column.\\nStack trace:\\n  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x3ef8ea) [0x7cb3038128ea]\\n  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x3f52e7) [0x7cb3038182e7]\\n  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x3f8188) [0x7cb30381b188]\\n  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x3a2367) [0x7cb3037c5367]\\n  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x2b0) [0x7cb303588ab0]\\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7cb3e164be2e]\\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7cb3e1648493]\\n  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7cb3e16713e9]\\n  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x7cb3e1670a00]\\n\\n') in model 1139 in generation 9: WindowRegression\n",
            "Model Number: 1140 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1141 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 1142 with model ARIMA in generation 9 of 10\n",
            "Model Number: 1143 with model ARIMA in generation 9 of 10\n",
            "Model Number: 1144 with model FBProphet in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1144 in generation 9: FBProphet\n",
            "Model Number: 1145 with model ARDL in generation 9 of 10\n",
            "Model Number: 1146 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1147 with model ETS in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 1147 in generation 9: ETS\n",
            "Model Number: 1148 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1149 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1150 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1151 with model UnobservedComponents in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 1151 in generation 9: UnobservedComponents\n",
            "Model Number: 1152 with model NVAR in generation 9 of 10\n",
            "Model Number: 1153 with model GLM in generation 9 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 1153 in generation 9: GLM\n",
            "Model Number: 1154 with model Theta in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1154 in generation 9: Theta\n",
            "Model Number: 1155 with model GLS in generation 9 of 10\n",
            "Model Number: 1156 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1157 with model ETS in generation 9 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:445: RuntimeWarning: divide by zero encountered in divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:143: RuntimeWarning: divide by zero encountered in divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1158 with model FBProphet in generation 9 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1159 with model GLS in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 1159 in generation 9: GLS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1160 with model NVAR in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1160 in generation 9: NVAR\n",
            "Model Number: 1161 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1162 with model Theta in generation 9 of 10\n",
            "Model Number: 1163 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1164 with model AverageValueNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1164 in generation 9: AverageValueNaive\n",
            "Model Number: 1165 with model GLS in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 1165 in generation 9: GLS\n",
            "Model Number: 1166 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1167 with model FBProphet in generation 9 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1168 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1169 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1170 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1171 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1172 with model GLM in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1172 in generation 9: GLM\n",
            "Model Number: 1173 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1174 with model ETS in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1174 in generation 9: ETS\n",
            "Model Number: 1175 with model MultivariateRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 1175 in generation 9: MultivariateRegression\n",
            "Model Number: 1176 with model NVAR in generation 9 of 10\n",
            "Model Number: 1177 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1178 with model ARIMA in generation 9 of 10\n",
            "Model Number: 1179 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1180 with model UnobservedComponents in generation 9 of 10\n",
            "New Generation: 10 of 10\n",
            "Model Number: 1181 with model ETS in generation 10 of 10\n",
            "Model Number: 1182 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1183 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1184 with model NVAR in generation 10 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1185 with model FBProphet in generation 10 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1186 with model Theta in generation 10 of 10\n",
            "Model Number: 1187 with model GLS in generation 10 of 10\n",
            "Model Number: 1188 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1189 with model ETS in generation 10 of 10\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on First with ValueError('Can only dampen the trend component')\n",
            "Model Number: 1190 with model GLS in generation 10 of 10\n",
            "Model Number: 1191 with model NVAR in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1191 in generation 10: NVAR\n",
            "Model Number: 1192 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1193 with model FBProphet in generation 10 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1194 with model Theta in generation 10 of 10\n",
            "Model Number: 1195 with model FBProphet in generation 10 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1196 with model ETS in generation 10 of 10\n",
            "Model Number: 1197 with model UnobservedComponents in generation 10 of 10\n",
            "Template Eval Error: LinAlgError('Singular matrix') in model 1197 in generation 10: UnobservedComponents\n",
            "Model Number: 1198 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1199 with model ETS in generation 10 of 10\n",
            "Model Number: 1200 with model ARDL in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1200 in generation 10: ARDL\n",
            "Model Number: 1201 with model AverageValueNaive in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1201 in generation 10: AverageValueNaive\n",
            "Model Number: 1202 with model ETS in generation 10 of 10\n",
            "Model Number: 1203 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1204 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1205 with model Theta in generation 10 of 10\n",
            "Model Number: 1206 with model FBProphet in generation 10 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1207 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1208 with model ARIMA in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1208 in generation 10: ARIMA\n",
            "Model Number: 1209 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1210 with model UnobservedComponents in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 1210 in generation 10: UnobservedComponents\n",
            "Model Number: 1211 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1212 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1213 with model GLS in generation 10 of 10\n",
            "Model Number: 1214 with model FBProphet in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1214 in generation 10: FBProphet\n",
            "Model Number: 1215 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1216 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1217 with model GLS in generation 10 of 10\n",
            "Model Number: 1218 with model WindowRegression in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1218 in generation 10: WindowRegression\n",
            "Model Number: 1219 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1220 with model Theta in generation 10 of 10\n",
            "Model Number: 1221 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1222 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1223 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1224 with model UnobservedComponents in generation 10 of 10\n",
            "Model Number: 1225 with model FBProphet in generation 10 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1226 with model GLS in generation 10 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1227 with model UnobservedComponents in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 1227 in generation 10: UnobservedComponents\n",
            "Model Number: 1228 with model ETS in generation 10 of 10\n",
            "Model Number: 1229 with model DatepartRegression in generation 10 of 10\n",
            "Model Number: 1230 with model DatepartRegression in generation 10 of 10\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.0031\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.0289\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.0280\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.0141\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.0028\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.0069\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.0105\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.0066\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.0028\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.0055\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.0043\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 1s 517ms/step - loss: 0.0019\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 0.0052\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 1s 551ms/step - loss: 0.0039\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.0019\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.0027\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.0041\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.0035\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.0015\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 0.0035\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.0034\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.0017\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.0023\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.0022\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 0.0020\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.0016\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.0044\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.0028\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.0028\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 0.0014\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.0039\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.0016\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.0017\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.0018\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.0017\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.0014\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.0016\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.0016\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.0011\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.0011\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 7.6031e-04\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 8.9844e-04\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 6.7799e-04\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 5.5939e-04\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 5.3366e-04\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 9.6234e-04\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.0012\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 9.2534e-04\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 5.1127e-04\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.0014\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 1231 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1232 with model FBProphet in generation 10 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: divide by zero encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1233 with model FBProphet in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer KalmanSmoothing failed on fit') in model 1233 in generation 10: FBProphet\n",
            "Model Number: 1234 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1235 with model FBProphet in generation 10 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1236 with model GLM in generation 10 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 1236 in generation 10: GLM\n",
            "Model Number: 1237 with model NVAR in generation 10 of 10\n",
            "Model Number: 1238 with model GLS in generation 10 of 10\n",
            "Model Number: 1239 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1240 with model ARDL in generation 10 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1406: RuntimeWarning: invalid value encountered in log\n",
            "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1241 with model Theta in generation 10 of 10\n",
            "Model Number: 1242 with model UnobservedComponents in generation 10 of 10\n",
            "Template Eval Error: LinAlgError('Singular matrix') in model 1242 in generation 10: UnobservedComponents\n",
            "Model Number: 1243 with model NVAR in generation 10 of 10\n",
            "Model Number: 1244 with model GLM in generation 10 of 10\n",
            "Model Number: 1245 with model UnobservedComponents in generation 10 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:307: DomainWarning: The InversePower link function does not respect the domain of the Gamma family.\n",
            "  warnings.warn((f\"The {type(family.link).__name__} link function \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1246 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1247 with model ETS in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1247 in generation 10: ETS\n",
            "Model Number: 1248 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1249 with model ETS in generation 10 of 10\n",
            "Model Number: 1250 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1251 with model FBProphet in generation 10 of 10\n",
            "No anomalies detected.\n",
            "Model Number: 1252 with model SeasonalNaive in generation 10 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1253 with model DatepartRegression in generation 10 of 10\n",
            "Model Number: 1254 with model SeasonalNaive in generation 10 of 10\n",
            "Model Number: 1255 with model FBProphet in generation 10 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (11). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 1256 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1257 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1258 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1259 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1260 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1261 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1262 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1263 with model Ensemble in generation 11 of Ensembles\n",
            "Validation Round: 1\n",
            "Model Number: 1 of 152 with model Ensemble for Validation 1\n",
            "📈 1 - Ensemble with avg smape 108.77: \n",
            "Model Number: 2 of 152 with model Ensemble for Validation 1\n",
            "2 - Ensemble with avg smape 110.27: \n",
            "Model Number: 3 of 152 with model UnobservedComponents for Validation 1\n",
            "3 - UnobservedComponents with avg smape 128.01: \n",
            "Model Number: 4 of 152 with model Ensemble for Validation 1\n",
            "4 - Ensemble with avg smape 137.16: \n",
            "Model Number: 5 of 152 with model Ensemble for Validation 1\n",
            "5 - Ensemble with avg smape 137.16: \n",
            "Model Number: 6 of 152 with model Ensemble for Validation 1\n",
            "6 - Ensemble with avg smape 125.75: \n",
            "Model Number: 7 of 152 with model Ensemble for Validation 1\n",
            "📈 7 - Ensemble with avg smape 96.3: \n",
            "Model Number: 8 of 152 with model Ensemble for Validation 1\n",
            "8 - Ensemble with avg smape 112.33: \n",
            "Model Number: 9 of 152 with model Ensemble for Validation 1\n",
            "📈 9 - Ensemble with avg smape 75.73: \n",
            "Model Number: 10 of 152 with model Theta for Validation 1\n",
            "10 - Theta with avg smape 133.92: \n",
            "Model Number: 11 of 152 with model AverageValueNaive for Validation 1\n",
            "11 - AverageValueNaive with avg smape 122.15: \n",
            "Model Number: 12 of 152 with model LastValueNaive for Validation 1\n",
            "12 - LastValueNaive with avg smape 152.06: \n",
            "Model Number: 13 of 152 with model GLS for Validation 1\n",
            "📈 13 - GLS with avg smape 57.47: \n",
            "Model Number: 14 of 152 with model GLS for Validation 1\n",
            "14 - GLS with avg smape 57.47: \n",
            "Model Number: 15 of 152 with model GLS for Validation 1\n",
            "15 - GLS with avg smape 57.47: \n",
            "Model Number: 16 of 152 with model NVAR for Validation 1\n",
            "16 - NVAR with avg smape 200.0: \n",
            "Model Number: 17 of 152 with model NVAR for Validation 1\n",
            "17 - NVAR with avg smape 200.0: \n",
            "Model Number: 18 of 152 with model NVAR for Validation 1\n",
            "18 - NVAR with avg smape 200.0: \n",
            "Model Number: 19 of 152 with model FBProphet for Validation 1\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 19 in generation 0: FBProphet\n",
            "Model Number: 20 of 152 with model LastValueNaive for Validation 1\n",
            "20 - LastValueNaive with avg smape 152.06: \n",
            "Model Number: 21 of 152 with model LastValueNaive for Validation 1\n",
            "21 - LastValueNaive with avg smape 152.06: \n",
            "Model Number: 22 of 152 with model ETS for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (7). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22 - ETS with avg smape 57.62: \n",
            "Model Number: 23 of 152 with model ETS for Validation 1\n",
            "23 - ETS with avg smape 57.62: \n",
            "Model Number: 24 of 152 with model Theta for Validation 1\n",
            "📈 24 - Theta with avg smape 54.25: \n",
            "Model Number: 25 of 152 with model GLS for Validation 1\n",
            "25 - GLS with avg smape 122.13: \n",
            "Model Number: 26 of 152 with model FBProphet for Validation 1\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 26 in generation 0: FBProphet\n",
            "Model Number: 27 of 152 with model UnobservedComponents for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (7). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27 - UnobservedComponents with avg smape 85.52: \n",
            "Model Number: 28 of 152 with model LastValueNaive for Validation 1\n",
            "28 - LastValueNaive with avg smape 138.18: \n",
            "Model Number: 29 of 152 with model LastValueNaive for Validation 1\n",
            "29 - LastValueNaive with avg smape 138.18: \n",
            "Model Number: 30 of 152 with model LastValueNaive for Validation 1\n",
            "30 - LastValueNaive with avg smape 138.18: \n",
            "Model Number: 31 of 152 with model LastValueNaive for Validation 1\n",
            "31 - LastValueNaive with avg smape 153.89: \n",
            "Model Number: 32 of 152 with model FBProphet for Validation 1\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 32 in generation 0: FBProphet\n",
            "Model Number: 33 of 152 with model LastValueNaive for Validation 1\n",
            "33 - LastValueNaive with avg smape 103.52: \n",
            "Model Number: 34 of 152 with model SeasonalNaive for Validation 1\n",
            "34 - SeasonalNaive with avg smape 80.95: \n",
            "Model Number: 35 of 152 with model SeasonalNaive for Validation 1\n",
            "35 - SeasonalNaive with avg smape 80.95: \n",
            "Model Number: 36 of 152 with model SeasonalNaive for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (7). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36 - SeasonalNaive with avg smape 80.95: \n",
            "Model Number: 37 of 152 with model SeasonalNaive for Validation 1\n",
            "37 - SeasonalNaive with avg smape 80.95: \n",
            "Model Number: 38 of 152 with model LastValueNaive for Validation 1\n",
            "38 - LastValueNaive with avg smape 108.27: \n",
            "Model Number: 39 of 152 with model AverageValueNaive for Validation 1\n",
            "39 - AverageValueNaive with avg smape 85.41: \n",
            "Model Number: 40 of 152 with model AverageValueNaive for Validation 1\n",
            "40 - AverageValueNaive with avg smape 85.41: \n",
            "Model Number: 41 of 152 with model FBProphet for Validation 1\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 41 in generation 0: FBProphet\n",
            "Model Number: 42 of 152 with model FBProphet for Validation 1\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 42 in generation 0: FBProphet\n",
            "Model Number: 43 of 152 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (7). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (7). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43 - FBProphet with avg smape 93.03: \n",
            "Model Number: 44 of 152 with model FBProphet for Validation 1\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 44 in generation 0: FBProphet\n",
            "Model Number: 45 of 152 with model FBProphet for Validation 1\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 45 in generation 0: FBProphet\n",
            "Model Number: 46 of 152 with model FBProphet for Validation 1\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 46 in generation 0: FBProphet\n",
            "Model Number: 47 of 152 with model Theta for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (7). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (7). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (7). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📈 47 - Theta with avg smape 44.05: \n",
            "Model Number: 48 of 152 with model Theta for Validation 1\n",
            "48 - Theta with avg smape 95.95: \n",
            "Model Number: 49 of 152 with model AverageValueNaive for Validation 1\n",
            "49 - AverageValueNaive with avg smape 92.4: \n",
            "Model Number: 50 of 152 with model WindowRegression for Validation 1\n",
            "50 - WindowRegression with avg smape 85.79: \n",
            "Model Number: 51 of 152 with model NVAR for Validation 1\n",
            "51 - NVAR with avg smape 167.93: \n",
            "Model Number: 52 of 152 with model NVAR for Validation 1\n",
            "52 - NVAR with avg smape 167.93: \n",
            "Model Number: 53 of 152 with model SeasonalNaive for Validation 1\n",
            "53 - SeasonalNaive with avg smape 84.48: \n",
            "Model Number: 54 of 152 with model SeasonalNaive for Validation 1\n",
            "54 - SeasonalNaive with avg smape 109.08: \n",
            "Model Number: 55 of 152 with model Theta for Validation 1\n",
            "55 - Theta with avg smape 88.36: \n",
            "Model Number: 56 of 152 with model Theta for Validation 1\n",
            "56 - Theta with avg smape 102.17: \n",
            "Model Number: 57 of 152 with model Theta for Validation 1\n",
            "57 - Theta with avg smape 88.99: \n",
            "Model Number: 58 of 152 with model GLS for Validation 1\n",
            "58 - GLS with avg smape 89.49: \n",
            "Model Number: 59 of 152 with model GLS for Validation 1\n",
            "59 - GLS with avg smape 89.49: \n",
            "Model Number: 60 of 152 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 7s 7s/step - loss: 20.5045\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 20.4977\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 1s 504ms/step - loss: 20.4911\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 20.4863\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 20.4776\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 20.4692\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 20.4644\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 20.4485\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 20.4337\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 20.4314\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 20.4114\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 20.3867\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 20.3766\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 20.3393\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 20.2848\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 20.2593\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 20.1566\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 20.1453\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 20.0265\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 19.8352\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 19.8876\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 19.9575\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 19.9904\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 19.9388\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 19.9291\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 19.8212\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 19.8024\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 19.8411\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 19.8557\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 19.9151\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 19.8691\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 19.8949\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 19.7796\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 19.7060\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 19.7108\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 1s 515ms/step - loss: 19.7241\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 1s 522ms/step - loss: 19.6892\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 19.7275\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 19.6213\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 19.7456\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 19.6788\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 19.6560\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 19.6441\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 19.6452\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 19.5831\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 19.6672\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 19.4972\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 19.6234\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 19.5498\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 19.4835\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "60 - DatepartRegression with avg smape 89.93: \n",
            "Model Number: 61 of 152 with model GLM for Validation 1\n",
            "61 - GLM with avg smape 89.51: \n",
            "Model Number: 62 of 152 with model DatepartRegression for Validation 1\n",
            "62 - DatepartRegression with avg smape 108.57: \n",
            "Model Number: 63 of 152 with model MultivariateRegression for Validation 1\n",
            "63 - MultivariateRegression with avg smape 89.51: \n",
            "Model Number: 64 of 152 with model GLM for Validation 1\n",
            "64 - GLM with avg smape 89.85: \n",
            "Model Number: 65 of 152 with model ETS for Validation 1\n",
            "65 - ETS with avg smape 89.51: \n",
            "Model Number: 66 of 152 with model AverageValueNaive for Validation 1\n",
            "📈 66 - AverageValueNaive with avg smape 34.79: \n",
            "Model Number: 67 of 152 with model ETS for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67 - ETS with avg smape 140.23: \n",
            "Model Number: 68 of 152 with model Theta for Validation 1\n",
            "68 - Theta with avg smape 87.48: \n",
            "Model Number: 69 of 152 with model ETS for Validation 1\n",
            "69 - ETS with avg smape 152.06: \n",
            "Model Number: 70 of 152 with model ETS for Validation 1\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on First with ValueError('Can only dampen the trend component')\n",
            "70 - ETS with avg smape 136.37: \n",
            "Model Number: 71 of 152 with model AverageValueNaive for Validation 1\n",
            "71 - AverageValueNaive with avg smape 136.37: \n",
            "Model Number: 72 of 152 with model NVAR for Validation 1\n",
            "72 - NVAR with avg smape 122.77: \n",
            "Model Number: 73 of 152 with model NVAR for Validation 1\n",
            "73 - NVAR with avg smape 122.78: \n",
            "Model Number: 74 of 152 with model NVAR for Validation 1\n",
            "74 - NVAR with avg smape 131.58: \n",
            "Model Number: 75 of 152 with model NVAR for Validation 1\n",
            "75 - NVAR with avg smape 185.95: \n",
            "Model Number: 76 of 152 with model Theta for Validation 1\n",
            "76 - Theta with avg smape 54.27: \n",
            "Model Number: 77 of 152 with model ETS for Validation 1\n",
            "77 - ETS with avg smape 92.4: \n",
            "Model Number: 78 of 152 with model UnobservedComponents for Validation 1\n",
            "📈 78 - UnobservedComponents with avg smape 33.88: \n",
            "Model Number: 79 of 152 with model WindowRegression for Validation 1\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 79 in generation 0: WindowRegression\n",
            "Model Number: 80 of 152 with model AverageValueNaive for Validation 1\n",
            "80 - AverageValueNaive with avg smape 122.15: \n",
            "Model Number: 81 of 152 with model GLS for Validation 1\n",
            "81 - GLS with avg smape 92.28: \n",
            "Model Number: 82 of 152 with model GLS for Validation 1\n",
            "82 - GLS with avg smape 92.28: \n",
            "Model Number: 83 of 152 with model GLS for Validation 1\n",
            "83 - GLS with avg smape 92.28: \n",
            "Model Number: 84 of 152 with model ConstantNaive for Validation 1\n",
            "84 - ConstantNaive with avg smape 89.51: \n",
            "Model Number: 85 of 152 with model ConstantNaive for Validation 1\n",
            "85 - ConstantNaive with avg smape 89.51: \n",
            "Model Number: 86 of 152 with model AverageValueNaive for Validation 1\n",
            "86 - AverageValueNaive with avg smape 87.0: \n",
            "Model Number: 87 of 152 with model SeasonalNaive for Validation 1\n",
            "87 - SeasonalNaive with avg smape 134.52: \n",
            "Model Number: 88 of 152 with model ConstantNaive for Validation 1\n",
            "88 - ConstantNaive with avg smape 128.21: \n",
            "Model Number: 89 of 152 with model ConstantNaive for Validation 1\n",
            "89 - ConstantNaive with avg smape 128.14: \n",
            "Model Number: 90 of 152 with model WindowRegression for Validation 1\n",
            "90 - WindowRegression with avg smape 86.83: \n",
            "Model Number: 91 of 152 with model ConstantNaive for Validation 1\n",
            "91 - ConstantNaive with avg smape 53.27: \n",
            "Model Number: 92 of 152 with model ConstantNaive for Validation 1\n",
            "92 - ConstantNaive with avg smape 53.27: \n",
            "Model Number: 93 of 152 with model ConstantNaive for Validation 1\n",
            "93 - ConstantNaive with avg smape 53.27: \n",
            "Model Number: 94 of 152 with model SeasonalNaive for Validation 1\n",
            "94 - SeasonalNaive with avg smape 95.13: \n",
            "Model Number: 95 of 152 with model AverageValueNaive for Validation 1\n",
            "95 - AverageValueNaive with avg smape 142.57: \n",
            "Model Number: 96 of 152 with model ConstantNaive for Validation 1\n",
            "📈 96 - ConstantNaive with avg smape 32.19: \n",
            "Model Number: 97 of 152 with model ConstantNaive for Validation 1\n",
            "97 - ConstantNaive with avg smape 32.19: \n",
            "Model Number: 98 of 152 with model ETS for Validation 1\n",
            "98 - ETS with avg smape 52.68: \n",
            "Model Number: 99 of 152 with model SeasonalNaive for Validation 1\n",
            "99 - SeasonalNaive with avg smape 95.55: \n",
            "Model Number: 100 of 152 with model ETS for Validation 1\n",
            "100 - ETS with avg smape 106.77: \n",
            "Model Number: 101 of 152 with model UnobservedComponents for Validation 1\n",
            "101 - UnobservedComponents with avg smape 157.68: \n",
            "Model Number: 102 of 152 with model UnobservedComponents for Validation 1\n",
            "102 - UnobservedComponents with avg smape 157.68: \n",
            "Model Number: 103 of 152 with model WindowRegression for Validation 1\n",
            "103 - WindowRegression with avg smape 63.86: \n",
            "Model Number: 104 of 152 with model UnobservedComponents for Validation 1\n",
            "104 - UnobservedComponents with avg smape 65.77: \n",
            "Model Number: 105 of 152 with model ARIMA for Validation 1\n",
            "105 - ARIMA with avg smape 67.3: \n",
            "Model Number: 106 of 152 with model ARDL for Validation 1\n",
            "106 - ARDL with avg smape 77.68: \n",
            "Model Number: 107 of 152 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 6s 6s/step - loss: 1.0077\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 1.0152\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 1.0095\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 1.0076\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 1.0091\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 1.0112\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 1.0097\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 1.0085\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 1.0081\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 1.0082\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 1.0055\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 1.0057\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 1.0023\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 1.0049\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 1.0018\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 1.0022\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 1.0042\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 1.0031\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 1.0021\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 1.0031\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 1.0014\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 0.9972\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 1s 594ms/step - loss: 1.0026\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 0.9981\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 0.9987\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.9974\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.9963\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.9886\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.9851\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.9879\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.9859\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.9861\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.9841\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.9628\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.9573\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 0.9496\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 0.9347\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 0.9126\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.8977\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.8795\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.8391\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.7912\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.7546\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.7675\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.7818\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.7500\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.7091\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.7378\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.7559\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.7478\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "107 - DatepartRegression with avg smape 50.97: \n",
            "Model Number: 108 of 152 with model GLM for Validation 1\n",
            "108 - GLM with avg smape 161.23: \n",
            "Model Number: 109 of 152 with model ARIMA for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1257: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "109 - ARIMA with avg smape 94.47: \n",
            "Model Number: 110 of 152 with model ARIMA for Validation 1\n",
            "110 - ARIMA with avg smape 86.23: \n",
            "Model Number: 111 of 152 with model DatepartRegression for Validation 1\n",
            "111 - DatepartRegression with avg smape 38.61: \n",
            "Model Number: 112 of 152 with model DatepartRegression for Validation 1\n",
            "112 - DatepartRegression with avg smape 101.35: \n",
            "Model Number: 113 of 152 with model DatepartRegression for Validation 1\n",
            "113 - DatepartRegression with avg smape 101.35: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (10) is greater than the total number of samples (7). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 114 of 152 with model DatepartRegression for Validation 1\n",
            "114 - DatepartRegression with avg smape 63.17: \n",
            "Model Number: 115 of 152 with model UnobservedComponents for Validation 1\n",
            "115 - UnobservedComponents with avg smape 54.77: \n",
            "Model Number: 116 of 152 with model WindowRegression for Validation 1\n",
            "116 - WindowRegression with avg smape 109.38: \n",
            "Model Number: 117 of 152 with model UnobservedComponents for Validation 1\n",
            "117 - UnobservedComponents with avg smape 95.77: \n",
            "Model Number: 118 of 152 with model DatepartRegression for Validation 1\n",
            "118 - DatepartRegression with avg smape 109.85: \n",
            "Model Number: 119 of 152 with model DatepartRegression for Validation 1\n",
            "119 - DatepartRegression with avg smape 123.66: \n",
            "Model Number: 120 of 152 with model UnobservedComponents for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (10) is greater than the total number of samples (7). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120 - UnobservedComponents with avg smape 157.83: \n",
            "Model Number: 121 of 152 with model WindowRegression for Validation 1\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 2 is required.') in model 121 in generation 0: WindowRegression\n",
            "Model Number: 122 of 152 with model ARIMA for Validation 1\n",
            "122 - ARIMA with avg smape 40.76: \n",
            "Model Number: 123 of 152 with model MultivariateRegression for Validation 1\n",
            "123 - MultivariateRegression with avg smape 41.84: \n",
            "Model Number: 124 of 152 with model ARIMA for Validation 1\n",
            "124 - ARIMA with avg smape 36.54: \n",
            "Model Number: 125 of 152 with model WindowRegression for Validation 1\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nBayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 125 in generation 0: WindowRegression\n",
            "Model Number: 126 of 152 with model GLM for Validation 1\n",
            "126 - GLM with avg smape 145.23: \n",
            "Model Number: 127 of 152 with model WindowRegression for Validation 1\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 127 in generation 0: WindowRegression\n",
            "Model Number: 128 of 152 with model ARDL for Validation 1\n",
            "128 - ARDL with avg smape 143.96: \n",
            "Model Number: 129 of 152 with model ARIMA for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:307: DomainWarning: The InversePower link function does not respect the domain of the Gamma family.\n",
            "  warnings.warn((f\"The {type(family.link).__name__} link function \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "129 - ARIMA with avg smape 42.16: \n",
            "Model Number: 130 of 152 with model ARIMA for Validation 1\n",
            "130 - ARIMA with avg smape 36.45: \n",
            "Model Number: 131 of 152 with model GLM for Validation 1\n",
            "📈 131 - GLM with avg smape 32.12: \n",
            "Model Number: 132 of 152 with model GLM for Validation 1\n",
            "📈 132 - GLM with avg smape 31.87: \n",
            "Model Number: 133 of 152 with model ARIMA for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "133 - ARIMA with avg smape 40.58: \n",
            "Model Number: 134 of 152 with model ARIMA for Validation 1\n",
            "📈 134 - ARIMA with avg smape 29.98: \n",
            "Model Number: 135 of 152 with model GLM for Validation 1\n",
            "135 - GLM with avg smape 103.08: \n",
            "Model Number: 136 of 152 with model ARDL for Validation 1\n",
            "136 - ARDL with avg smape 165.25: \n",
            "Model Number: 137 of 152 with model WindowRegression for Validation 1\n",
            "137 - WindowRegression with avg smape 142.45: \n",
            "Model Number: 138 of 152 with model ARDL for Validation 1\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (6) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (3).') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0 and predict             HolidayFlag_US\\n2020-12-31             0.0\\n2021-01-31             0.0\\n2021-02-28             0.0\\n2021-03-31             0.0\") in model 138 in generation 0: ARDL\n",
            "Model Number: 139 of 152 with model ARDL for Validation 1\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 139 in generation 0: ARDL\n",
            "Model Number: 140 of 152 with model GLM for Validation 1\n",
            "140 - GLM with avg smape 117.2: \n",
            "Model Number: 141 of 152 with model MultivariateRegression for Validation 1\n",
            "141 - MultivariateRegression with avg smape 43.07: \n",
            "Model Number: 142 of 152 with model MultivariateRegression for Validation 1\n",
            "142 - MultivariateRegression with avg smape 33.98: \n",
            "Model Number: 143 of 152 with model GLM for Validation 1\n",
            "143 - GLM with avg smape 70.45: \n",
            "Model Number: 144 of 152 with model ARDL for Validation 1\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (5) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (4).') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0 and predict             HolidayFlag_US\\n2020-12-31             0.0\\n2021-01-31             0.0\\n2021-02-28             0.0\\n2021-03-31             0.0\") in model 144 in generation 0: ARDL\n",
            "Model Number: 145 of 152 with model MultivariateRegression for Validation 1\n",
            "145 - MultivariateRegression with avg smape 170.13: \n",
            "Model Number: 146 of 152 with model ARDL for Validation 1\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (6) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (5).') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0 and predict             HolidayFlag_US\\n2020-12-31             0.0\\n2021-01-31             0.0\\n2021-02-28             0.0\\n2021-03-31             0.0\") in model 146 in generation 0: ARDL\n",
            "Model Number: 147 of 152 with model ARDL for Validation 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/_loss/link.py:172: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.log(y_pred, out=out)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/glm.py:284: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147 - ARDL with avg smape 108.66: \n",
            "Model Number: 148 of 152 with model MultivariateRegression for Validation 1\n",
            "148 - MultivariateRegression with avg smape 149.18: \n",
            "Model Number: 149 of 152 with model MultivariateRegression for Validation 1\n",
            "149 - MultivariateRegression with avg smape 149.18: \n",
            "Model Number: 150 of 152 with model ARDL for Validation 1\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (5) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (4).') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0 and predict             HolidayFlag_US\\n2020-12-31             0.0\\n2021-01-31             0.0\\n2021-02-28             0.0\\n2021-03-31             0.0\") in model 150 in generation 0: ARDL\n",
            "Model Number: 151 of 152 with model MultivariateRegression for Validation 1\n",
            "151 - MultivariateRegression with avg smape 65.01: \n",
            "Model Number: 152 of 152 with model MultivariateRegression for Validation 1\n",
            "152 - MultivariateRegression with avg smape 43.07: \n",
            "Validation Round: 2\n",
            "Model Number: 1 of 152 with model Ensemble for Validation 2\n",
            "📈 1 - Ensemble with avg smape 72.54: \n",
            "Model Number: 2 of 152 with model Ensemble for Validation 2\n",
            "📈 2 - Ensemble with avg smape 70.72: \n",
            "Model Number: 3 of 152 with model UnobservedComponents for Validation 2\n",
            "3 - UnobservedComponents with avg smape 76.76: \n",
            "Model Number: 4 of 152 with model Ensemble for Validation 2\n",
            "4 - Ensemble with avg smape 72.69: \n",
            "Model Number: 5 of 152 with model Ensemble for Validation 2\n",
            "5 - Ensemble with avg smape 72.69: \n",
            "Model Number: 6 of 152 with model Ensemble for Validation 2\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4245, in _fit\n",
            "    df = self._fit_one(df, i)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4229, in _fit_one\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 641, in fit_transform\n",
            "    self.fit(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 629, in fit\n",
            "    self.fit_sin(X, df[col].to_numpy(), method=self.method)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 591, in fit_sin\n",
            "    popt, pcov = curve_fit(sinfunc, tt, yy, p0=guess, maxfev=10000, method=method)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/optimize/_minpack_py.py\", line 961, in curve_fit\n",
            "    raise TypeError(f\"The number of func parameters={n} must not\"\n",
            "TypeError: The number of func parameters=4 must not exceed the number of data points=3\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 1209, in model_forecast\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 1313, in model_forecast\n",
            "    model = model.fit(df_train_low, future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 775, in fit\n",
            "    df_train_transformed = self.transformer_object._fit(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4247, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer SinTrend failed on fit\n",
            "\n",
            "FAILED: Ensemble BestN component 6 of 5 GLS with error: Exception('Transformer SinTrend failed on fit')\n",
            "6 - Ensemble with avg smape 73.52: \n",
            "Model Number: 7 of 152 with model Ensemble for Validation 2\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4245, in _fit\n",
            "    df = self._fit_one(df, i)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4229, in _fit_one\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 641, in fit_transform\n",
            "    self.fit(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 629, in fit\n",
            "    self.fit_sin(X, df[col].to_numpy(), method=self.method)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 591, in fit_sin\n",
            "    popt, pcov = curve_fit(sinfunc, tt, yy, p0=guess, maxfev=10000, method=method)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/optimize/_minpack_py.py\", line 961, in curve_fit\n",
            "    raise TypeError(f\"The number of func parameters={n} must not\"\n",
            "TypeError: The number of func parameters=4 must not exceed the number of data points=3\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 1209, in model_forecast\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 1313, in model_forecast\n",
            "    model = model.fit(df_train_low, future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 775, in fit\n",
            "    df_train_transformed = self.transformer_object._fit(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4247, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer SinTrend failed on fit\n",
            "\n",
            "FAILED: Ensemble BestN component 2 of 3 Theta with error: Exception('Transformer SinTrend failed on fit')\n",
            "📈 7 - Ensemble with avg smape 69.2: \n",
            "Model Number: 8 of 152 with model Ensemble for Validation 2\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4245, in _fit\n",
            "    df = self._fit_one(df, i)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4229, in _fit_one\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 641, in fit_transform\n",
            "    self.fit(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 629, in fit\n",
            "    self.fit_sin(X, df[col].to_numpy(), method=self.method)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 591, in fit_sin\n",
            "    popt, pcov = curve_fit(sinfunc, tt, yy, p0=guess, maxfev=10000, method=method)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/optimize/_minpack_py.py\", line 961, in curve_fit\n",
            "    raise TypeError(f\"The number of func parameters={n} must not\"\n",
            "TypeError: The number of func parameters=4 must not exceed the number of data points=3\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 1209, in model_forecast\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 1313, in model_forecast\n",
            "    model = model.fit(df_train_low, future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 775, in fit\n",
            "    df_train_transformed = self.transformer_object._fit(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4247, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer SinTrend failed on fit\n",
            "\n",
            "FAILED: Ensemble BestN component 6 of 5 GLS with error: Exception('Transformer SinTrend failed on fit')\n",
            "8 - Ensemble with avg smape 75.11: \n",
            "Model Number: 9 of 152 with model Ensemble for Validation 2\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4245, in _fit\n",
            "    df = self._fit_one(df, i)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4229, in _fit_one\n",
            "    df = self.transformers[i].fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 641, in fit_transform\n",
            "    self.fit(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 629, in fit\n",
            "    self.fit_sin(X, df[col].to_numpy(), method=self.method)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 591, in fit_sin\n",
            "    popt, pcov = curve_fit(sinfunc, tt, yy, p0=guess, maxfev=10000, method=method)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/optimize/_minpack_py.py\", line 961, in curve_fit\n",
            "    raise TypeError(f\"The number of func parameters={n} must not\"\n",
            "TypeError: The number of func parameters=4 must not exceed the number of data points=3\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 1209, in model_forecast\n",
            "    df_forecast = model_forecast(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 1313, in model_forecast\n",
            "    model = model.fit(df_train_low, future_regressor_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_model.py\", line 775, in fit\n",
            "    df_train_transformed = self.transformer_object._fit(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autots/tools/transform.py\", line 4247, in _fit\n",
            "    raise Exception(\n",
            "Exception: Transformer SinTrend failed on fit\n",
            "\n",
            "FAILED: Ensemble BestN component 2 of 5 Theta with error: Exception('Transformer SinTrend failed on fit')\n",
            "9 - Ensemble with avg smape 84.48: \n",
            "Model Number: 10 of 152 with model Theta for Validation 2\n",
            "10 - Theta with avg smape 133.54: \n",
            "Model Number: 11 of 152 with model AverageValueNaive for Validation 2\n",
            "11 - AverageValueNaive with avg smape 78.44: \n",
            "Model Number: 12 of 152 with model LastValueNaive for Validation 2\n",
            "12 - LastValueNaive with avg smape 133.54: \n",
            "Model Number: 13 of 152 with model GLS for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 13 in generation 0: GLS\n",
            "Model Number: 14 of 152 with model GLS for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 14 in generation 0: GLS\n",
            "Model Number: 15 of 152 with model GLS for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 15 in generation 0: GLS\n",
            "Model Number: 16 of 152 with model NVAR for Validation 2\n",
            "Template Eval Error: IndexError('index -4 is out of bounds for axis 1 with size 3') in model 16 in generation 0: NVAR\n",
            "Model Number: 17 of 152 with model NVAR for Validation 2\n",
            "Template Eval Error: IndexError('index -4 is out of bounds for axis 1 with size 3') in model 17 in generation 0: NVAR\n",
            "Model Number: 18 of 152 with model NVAR for Validation 2\n",
            "Template Eval Error: IndexError('index -4 is out of bounds for axis 1 with size 3') in model 18 in generation 0: NVAR\n",
            "Model Number: 19 of 152 with model FBProphet for Validation 2\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 19 in generation 0: FBProphet\n",
            "Model Number: 20 of 152 with model LastValueNaive for Validation 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (3). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20 - LastValueNaive with avg smape 133.54: \n",
            "Model Number: 21 of 152 with model LastValueNaive for Validation 2\n",
            "Template Eval Error: Exception('Transformer PowerTransformer failed on fit') in model 21 in generation 0: LastValueNaive\n",
            "Model Number: 22 of 152 with model ETS for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 22 in generation 0: ETS\n",
            "Model Number: 23 of 152 with model ETS for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 23 in generation 0: ETS\n",
            "Model Number: 24 of 152 with model Theta for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 24 in generation 0: Theta\n",
            "Model Number: 25 of 152 with model GLS for Validation 2\n",
            "25 - GLS with avg smape 78.38: \n",
            "Model Number: 26 of 152 with model FBProphet for Validation 2\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 26 in generation 0: FBProphet\n",
            "Model Number: 27 of 152 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (3). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27 - UnobservedComponents with avg smape 90.31: \n",
            "Model Number: 28 of 152 with model LastValueNaive for Validation 2\n",
            "28 - LastValueNaive with avg smape 70.29: \n",
            "Model Number: 29 of 152 with model LastValueNaive for Validation 2\n",
            "29 - LastValueNaive with avg smape 70.29: \n",
            "Model Number: 30 of 152 with model LastValueNaive for Validation 2\n",
            "30 - LastValueNaive with avg smape 70.29: \n",
            "Model Number: 31 of 152 with model LastValueNaive for Validation 2\n",
            "31 - LastValueNaive with avg smape 133.54: \n",
            "Model Number: 32 of 152 with model FBProphet for Validation 2\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 32 in generation 0: FBProphet\n",
            "Model Number: 33 of 152 with model LastValueNaive for Validation 2\n",
            "Template Eval Error: Exception('Transformer QuantileTransformer failed on fit') in model 33 in generation 0: LastValueNaive\n",
            "Model Number: 34 of 152 with model SeasonalNaive for Validation 2\n",
            "34 - SeasonalNaive with avg smape 91.64: \n",
            "Model Number: 35 of 152 with model SeasonalNaive for Validation 2\n",
            "35 - SeasonalNaive with avg smape 91.64: \n",
            "Model Number: 36 of 152 with model SeasonalNaive for Validation 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (3). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36 - SeasonalNaive with avg smape 91.64: \n",
            "Model Number: 37 of 152 with model SeasonalNaive for Validation 2\n",
            "37 - SeasonalNaive with avg smape 91.64: \n",
            "Model Number: 38 of 152 with model LastValueNaive for Validation 2\n",
            "38 - LastValueNaive with avg smape 71.71: \n",
            "Model Number: 39 of 152 with model AverageValueNaive for Validation 2\n",
            "39 - AverageValueNaive with avg smape 88.4: \n",
            "Model Number: 40 of 152 with model AverageValueNaive for Validation 2\n",
            "40 - AverageValueNaive with avg smape 88.4: \n",
            "Model Number: 41 of 152 with model FBProphet for Validation 2\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 41 in generation 0: FBProphet\n",
            "Model Number: 42 of 152 with model FBProphet for Validation 2\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 42 in generation 0: FBProphet\n",
            "Model Number: 43 of 152 with model FBProphet for Validation 2\n",
            "43 - FBProphet with avg smape 95.36: \n",
            "Model Number: 44 of 152 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (3). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (3). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (3). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 44 in generation 0: FBProphet\n",
            "Model Number: 45 of 152 with model FBProphet for Validation 2\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 45 in generation 0: FBProphet\n",
            "Model Number: 46 of 152 with model FBProphet for Validation 2\n",
            "No anomalies detected.\n",
            "Template Eval Error: ValueError('more than 1 year of data is required for holiday detection.') in model 46 in generation 0: FBProphet\n",
            "Model Number: 47 of 152 with model Theta for Validation 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (3). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (20) is greater than the total number of samples (3). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47 - Theta with avg smape 98.2: \n",
            "Model Number: 48 of 152 with model Theta for Validation 2\n",
            "48 - Theta with avg smape 92.93: \n",
            "Model Number: 49 of 152 with model AverageValueNaive for Validation 2\n",
            "49 - AverageValueNaive with avg smape 84.99: \n",
            "Model Number: 50 of 152 with model WindowRegression for Validation 2\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 50 in generation 0: WindowRegression\n",
            "Model Number: 51 of 152 with model NVAR for Validation 2\n",
            "Template Eval Error: IndexError('index -4 is out of bounds for axis 1 with size 3') in model 51 in generation 0: NVAR\n",
            "Model Number: 52 of 152 with model NVAR for Validation 2\n",
            "Template Eval Error: IndexError('index -4 is out of bounds for axis 1 with size 3') in model 52 in generation 0: NVAR\n",
            "Model Number: 53 of 152 with model SeasonalNaive for Validation 2\n",
            "53 - SeasonalNaive with avg smape 84.97: \n",
            "Model Number: 54 of 152 with model SeasonalNaive for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 54 in generation 0: SeasonalNaive\n",
            "Model Number: 55 of 152 with model Theta for Validation 2\n",
            "55 - Theta with avg smape 90.62: \n",
            "Model Number: 56 of 152 with model Theta for Validation 2\n",
            "56 - Theta with avg smape 90.43: \n",
            "Model Number: 57 of 152 with model Theta for Validation 2\n",
            "57 - Theta with avg smape 90.75: \n",
            "Model Number: 58 of 152 with model GLS for Validation 2\n",
            "58 - GLS with avg smape 90.84: \n",
            "Model Number: 59 of 152 with model GLS for Validation 2\n",
            "59 - GLS with avg smape 90.84: \n",
            "Model Number: 60 of 152 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 8s 8s/step - loss: 13.3117\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 13.2904\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 13.2693\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 13.2403\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 13.2153\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 13.1867\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 13.1548\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 13.1028\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 13.0448\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 12.9842\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 12.8866\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 12.7747\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 12.6754\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 12.4391\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 12.3396\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 12.0174\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 11.7741\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 11.4709\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 11.3351\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 11.6469\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 11.3496\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 11.5256\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 11.5303\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 11.4630\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 11.2843\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 11.1584\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 11.1457\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 11.1676\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 11.0799\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 11.0959\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 11.1958\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 11.1097\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 11.1643\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 11.0354\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 11.0692\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 10.9240\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 11.0315\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 10.9477\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 11.0281\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 10.9047\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 11.0959\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 11.1853\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 10.9197\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 10.7269\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 10.7762\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 10.8859\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 10.8972\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 10.9392\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 1s 509ms/step - loss: 10.7777\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 10.6996\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "60 - DatepartRegression with avg smape 91.13: \n",
            "Model Number: 61 of 152 with model GLM for Validation 2\n",
            "61 - GLM with avg smape 90.84: \n",
            "Model Number: 62 of 152 with model DatepartRegression for Validation 2\n",
            "62 - DatepartRegression with avg smape 91.55: \n",
            "Model Number: 63 of 152 with model MultivariateRegression for Validation 2\n",
            "Template Eval Error: ValueError('Need at least 3 dates to infer frequency') in model 63 in generation 0: MultivariateRegression\n",
            "Model Number: 64 of 152 with model GLM for Validation 2\n",
            "64 - GLM with avg smape 90.84: \n",
            "Model Number: 65 of 152 with model ETS for Validation 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/links.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  t = np.exp(-z)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 - ETS with avg smape 90.84: \n",
            "Model Number: 66 of 152 with model AverageValueNaive for Validation 2\n",
            "66 - AverageValueNaive with avg smape 100.96: \n",
            "Model Number: 67 of 152 with model ETS for Validation 2\n",
            "67 - ETS with avg smape 78.68: \n",
            "Model Number: 68 of 152 with model Theta for Validation 2\n",
            "68 - Theta with avg smape 90.43: \n",
            "Model Number: 69 of 152 with model ETS for Validation 2\n",
            "69 - ETS with avg smape 133.54: \n",
            "Model Number: 70 of 152 with model ETS for Validation 2\n",
            "ETS error ValueError('Can only dampen the trend component')\n",
            "ETS failed on First with ValueError('Can only dampen the trend component')\n",
            "70 - ETS with avg smape 133.54: \n",
            "Model Number: 71 of 152 with model AverageValueNaive for Validation 2\n",
            "71 - AverageValueNaive with avg smape 133.54: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Number: 72 of 152 with model NVAR for Validation 2\n",
            "Template Eval Error: IndexError('index -4 is out of bounds for axis 1 with size 3') in model 72 in generation 0: NVAR\n",
            "Model Number: 73 of 152 with model NVAR for Validation 2\n",
            "Template Eval Error: IndexError('index -4 is out of bounds for axis 1 with size 3') in model 73 in generation 0: NVAR\n",
            "Model Number: 74 of 152 with model NVAR for Validation 2\n",
            "Template Eval Error: IndexError('index -4 is out of bounds for axis 1 with size 3') in model 74 in generation 0: NVAR\n",
            "Model Number: 75 of 152 with model NVAR for Validation 2\n",
            "Template Eval Error: IndexError('index -4 is out of bounds for axis 1 with size 3') in model 75 in generation 0: NVAR\n",
            "Model Number: 76 of 152 with model Theta for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 76 in generation 0: Theta\n",
            "Model Number: 77 of 152 with model ETS for Validation 2\n",
            "77 - ETS with avg smape 84.99: \n",
            "Model Number: 78 of 152 with model UnobservedComponents for Validation 2\n",
            "Template Eval Error: ValueError(\"'shape' elements cannot be negative\") in model 78 in generation 0: UnobservedComponents\n",
            "Model Number: 79 of 152 with model WindowRegression for Validation 2\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 79 in generation 0: WindowRegression\n",
            "Model Number: 80 of 152 with model AverageValueNaive for Validation 2\n",
            "80 - AverageValueNaive with avg smape 71.33: \n",
            "Model Number: 81 of 152 with model GLS for Validation 2\n",
            "81 - GLS with avg smape 85.02: \n",
            "Model Number: 82 of 152 with model GLS for Validation 2\n",
            "82 - GLS with avg smape 85.02: \n",
            "Model Number: 83 of 152 with model GLS for Validation 2\n",
            "83 - GLS with avg smape 85.02: \n",
            "Model Number: 84 of 152 with model ConstantNaive for Validation 2\n",
            "84 - ConstantNaive with avg smape 90.84: \n",
            "Model Number: 85 of 152 with model ConstantNaive for Validation 2\n",
            "85 - ConstantNaive with avg smape 90.84: \n",
            "Model Number: 86 of 152 with model AverageValueNaive for Validation 2\n",
            "86 - AverageValueNaive with avg smape 89.02: \n",
            "Model Number: 87 of 152 with model SeasonalNaive for Validation 2\n",
            "87 - SeasonalNaive with avg smape 133.54: \n",
            "Model Number: 88 of 152 with model ConstantNaive for Validation 2\n",
            "88 - ConstantNaive with avg smape 73.08: \n",
            "Model Number: 89 of 152 with model ConstantNaive for Validation 2\n",
            "89 - ConstantNaive with avg smape 73.01: \n",
            "Model Number: 90 of 152 with model WindowRegression for Validation 2\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 90 in generation 0: WindowRegression\n",
            "Model Number: 91 of 152 with model ConstantNaive for Validation 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.10/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "91 - ConstantNaive with avg smape 100.91: \n",
            "Model Number: 92 of 152 with model ConstantNaive for Validation 2\n",
            "92 - ConstantNaive with avg smape 100.91: \n",
            "Model Number: 93 of 152 with model ConstantNaive for Validation 2\n",
            "93 - ConstantNaive with avg smape 100.91: \n",
            "Model Number: 94 of 152 with model SeasonalNaive for Validation 2\n",
            "94 - SeasonalNaive with avg smape 82.95: \n",
            "Model Number: 95 of 152 with model AverageValueNaive for Validation 2\n",
            "95 - AverageValueNaive with avg smape 133.54: \n",
            "Model Number: 96 of 152 with model ConstantNaive for Validation 2\n",
            "96 - ConstantNaive with avg smape 102.34: \n",
            "Model Number: 97 of 152 with model ConstantNaive for Validation 2\n",
            "97 - ConstantNaive with avg smape 102.34: \n",
            "Model Number: 98 of 152 with model ETS for Validation 2\n",
            "98 - ETS with avg smape 98.76: \n",
            "Model Number: 99 of 152 with model SeasonalNaive for Validation 2\n",
            "99 - SeasonalNaive with avg smape 80.73: \n",
            "Model Number: 100 of 152 with model ETS for Validation 2\n",
            "100 - ETS with avg smape 85.44: \n",
            "Model Number: 101 of 152 with model UnobservedComponents for Validation 2\n",
            "101 - UnobservedComponents with avg smape 133.54: \n",
            "Model Number: 102 of 152 with model UnobservedComponents for Validation 2\n",
            "102 - UnobservedComponents with avg smape 133.54: \n",
            "Model Number: 103 of 152 with model WindowRegression for Validation 2\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 103 in generation 0: WindowRegression\n",
            "Model Number: 104 of 152 with model UnobservedComponents for Validation 2\n",
            "Template Eval Error: ValueError(\"'shape' elements cannot be negative\") in model 104 in generation 0: UnobservedComponents\n",
            "Model Number: 105 of 152 with model ARIMA for Validation 2\n",
            "105 - ARIMA with avg smape 200.0: \n",
            "Model Number: 106 of 152 with model ARDL for Validation 2\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (4) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (1).') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0 and predict             HolidayFlag_US\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0\") in model 106 in generation 0: ARDL\n",
            "Model Number: 107 of 152 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.6699\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.6743\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.6734\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.6643\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6604\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.6572\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 0.6513\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.6490\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6406\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.6405\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.6381\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.6254\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.6160\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6077\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.5924\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.5698\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.5593\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.5399\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.5245\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.4971\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.4506\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.3827\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.4048\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.3146\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.2833\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.1658\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.2697\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.1568\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.1771\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.1803\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.1913\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.1201\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.0895\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.1054\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.0968\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.0929\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.1216\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.1185\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.0734\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.0973\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.0356\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.0986\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.0847\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.0883\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.0938\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.0394\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.0572\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.0679\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.0871\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.0768\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "107 - DatepartRegression with avg smape 103.22: \n",
            "Model Number: 108 of 152 with model GLM for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 108 in generation 0: GLM\n",
            "Model Number: 109 of 152 with model ARIMA for Validation 2\n",
            "109 - ARIMA with avg smape 200.0: \n",
            "Model Number: 110 of 152 with model ARIMA for Validation 2\n",
            "Template Eval Error: Exception('Transformer Detrend failed on inverse') in model 110 in generation 0: ARIMA\n",
            "Model Number: 111 of 152 with model DatepartRegression for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 111 in generation 0: DatepartRegression\n",
            "Model Number: 112 of 152 with model DatepartRegression for Validation 2\n",
            "112 - DatepartRegression with avg smape 100.96: \n",
            "Model Number: 113 of 152 with model DatepartRegression for Validation 2\n",
            "113 - DatepartRegression with avg smape 100.96: \n",
            "Model Number: 114 of 152 with model DatepartRegression for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 114 in generation 0: DatepartRegression\n",
            "Model Number: 115 of 152 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (10) is greater than the total number of samples (3). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "115 - UnobservedComponents with avg smape 93.54: \n",
            "Model Number: 116 of 152 with model WindowRegression for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 116 in generation 0: WindowRegression\n",
            "Model Number: 117 of 152 with model UnobservedComponents for Validation 2\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 117 in generation 0: UnobservedComponents\n",
            "Model Number: 118 of 152 with model DatepartRegression for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 118 in generation 0: DatepartRegression\n",
            "Model Number: 119 of 152 with model DatepartRegression for Validation 2\n",
            "119 - DatepartRegression with avg smape 74.23: \n",
            "Model Number: 120 of 152 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_lof.py:282: UserWarning: n_neighbors (10) is greater than the total number of samples (3). n_neighbors will be set to (n_samples - 1) for estimation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120 - UnobservedComponents with avg smape 133.54: \n",
            "Model Number: 121 of 152 with model WindowRegression for Validation 2\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 2 is required.') in model 121 in generation 0: WindowRegression\n",
            "Model Number: 122 of 152 with model ARIMA for Validation 2\n",
            "122 - ARIMA with avg smape 78.64: \n",
            "Model Number: 123 of 152 with model MultivariateRegression for Validation 2\n",
            "Template Eval Error: ValueError('Need at least 3 dates to infer frequency') in model 123 in generation 0: MultivariateRegression\n",
            "Model Number: 124 of 152 with model ARIMA for Validation 2\n",
            "124 - ARIMA with avg smape 100.03: \n",
            "Model Number: 125 of 152 with model WindowRegression for Validation 2\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 125 in generation 0: WindowRegression\n",
            "Model Number: 126 of 152 with model GLM for Validation 2\n",
            "126 - GLM with avg smape 106.26: \n",
            "Model Number: 127 of 152 with model WindowRegression for Validation 2\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 127 in generation 0: WindowRegression\n",
            "Model Number: 128 of 152 with model ARDL for Validation 2\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (4) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (1).') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0 and predict             HolidayFlag_US\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0\") in model 128 in generation 0: ARDL\n",
            "Model Number: 129 of 152 with model ARIMA for Validation 2\n",
            "129 - ARIMA with avg smape 200.0: \n",
            "Model Number: 130 of 152 with model ARIMA for Validation 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:307: DomainWarning: The InversePower link function does not respect the domain of the Gamma family.\n",
            "  warnings.warn((f\"The {type(family.link).__name__} link function \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "130 - ARIMA with avg smape 115.87: \n",
            "Model Number: 131 of 152 with model GLM for Validation 2\n",
            "131 - GLM with avg smape 101.06: \n",
            "Model Number: 132 of 152 with model GLM for Validation 2\n",
            "132 - GLM with avg smape 101.1: \n",
            "Model Number: 133 of 152 with model ARIMA for Validation 2\n",
            "133 - ARIMA with avg smape 157.42: \n",
            "Model Number: 134 of 152 with model ARIMA for Validation 2\n",
            "134 - ARIMA with avg smape 128.45: \n",
            "Model Number: 135 of 152 with model GLM for Validation 2\n",
            "135 - GLM with avg smape 79.23: \n",
            "Model Number: 136 of 152 with model ARDL for Validation 2\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (4) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (1).') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0 and predict             HolidayFlag_US\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0\") in model 136 in generation 0: ARDL\n",
            "Model Number: 137 of 152 with model WindowRegression for Validation 2\n",
            "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 137 in generation 0: WindowRegression\n",
            "Model Number: 138 of 152 with model ARDL for Validation 2\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('negative dimensions are not allowed') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0 and predict             HolidayFlag_US\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0\") in model 138 in generation 0: ARDL\n",
            "Model Number: 139 of 152 with model ARDL for Validation 2\n",
            "Template Eval Error: Exception('Transformer HolidayTransformer failed on fit') in model 139 in generation 0: ARDL\n",
            "Model Number: 140 of 152 with model GLM for Validation 2\n",
            "Template Eval Error: Exception('Transformer SinTrend failed on fit') in model 140 in generation 0: GLM\n",
            "Model Number: 141 of 152 with model MultivariateRegression for Validation 2\n",
            "Template Eval Error: ValueError('Need at least 3 dates to infer frequency') in model 141 in generation 0: MultivariateRegression\n",
            "Model Number: 142 of 152 with model MultivariateRegression for Validation 2\n",
            "Template Eval Error: ValueError('Need at least 3 dates to infer frequency') in model 142 in generation 0: MultivariateRegression\n",
            "Model Number: 143 of 152 with model GLM for Validation 2\n",
            "143 - GLM with avg smape 93.21: \n",
            "Model Number: 144 of 152 with model ARDL for Validation 2\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('maxlag should be < nobs') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0 and predict             HolidayFlag_US\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0\") in model 144 in generation 0: ARDL\n",
            "Model Number: 145 of 152 with model MultivariateRegression for Validation 2\n",
            "Template Eval Error: ValueError('Need at least 3 dates to infer frequency') in model 145 in generation 0: MultivariateRegression\n",
            "Model Number: 146 of 152 with model ARDL for Validation 2\n",
            "Template Eval Error: Exception('Transformer AlignLastValue failed on fit') in model 146 in generation 0: ARDL\n",
            "Model Number: 147 of 152 with model ARDL for Validation 2\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('The number of regressors (3) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (1).') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0 and predict             HolidayFlag_US\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0\") in model 147 in generation 0: ARDL\n",
            "Model Number: 148 of 152 with model MultivariateRegression for Validation 2\n",
            "Template Eval Error: ValueError('Need at least 3 dates to infer frequency') in model 148 in generation 0: MultivariateRegression\n",
            "Model Number: 149 of 152 with model MultivariateRegression for Validation 2\n",
            "Template Eval Error: ValueError('Need at least 3 dates to infer frequency') in model 149 in generation 0: MultivariateRegression\n",
            "Model Number: 150 of 152 with model ARDL for Validation 2\n",
            "Template Eval Error: ValueError(\"ARDL series First failed with error ValueError('maxlag should be < nobs') exog train             HolidayFlag_US\\nperiod_end                \\n2020-05-31             0.0\\n2020-06-30             0.0\\n2020-07-31             0.0 and predict             HolidayFlag_US\\n2020-08-31             0.0\\n2020-09-30             0.0\\n2020-10-31             0.0\\n2020-11-30             0.0\") in model 150 in generation 0: ARDL\n",
            "Model Number: 151 of 152 with model MultivariateRegression for Validation 2\n",
            "Template Eval Error: ValueError('Need at least 3 dates to infer frequency') in model 151 in generation 0: MultivariateRegression\n",
            "Model Number: 152 of 152 with model MultivariateRegression for Validation 2\n",
            "Template Eval Error: ValueError('Need at least 3 dates to infer frequency') in model 152 in generation 0: MultivariateRegression\n",
            "Validation Round: 3\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2f721404b401>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAutoTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfrequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'simple'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'period_end'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'followers_gained'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_ts.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, df, date_col, value_col, id_col, future_regressor, weights, result_file, grouping_ids, validation_indexes)\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# run validations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_validations\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m             self._run_validations(\n\u001b[0m\u001b[1;32m   1382\u001b[0m                 \u001b[0mdf_wide_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_wide_numeric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                 \u001b[0mnum_validations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_validations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autots/evaluator/auto_ts.py\u001b[0m in \u001b[0;36m_run_validations\u001b[0;34m(self, df_wide_numeric, num_validations, validation_template, future_regressor, first_validation, skip_first_index)\u001b[0m\n\u001b[1;32m   1950\u001b[0m                 \u001b[0mcurrent_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_subset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m             val_df_train, val_df_test = simple_train_test_split(\n\u001b[0m\u001b[1;32m   1953\u001b[0m                 \u001b[0mdf_subset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m                 \u001b[0mforecast_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autots/tools/shaping.py\u001b[0m in \u001b[0;36msimple_train_test_split\u001b[0;34m(df, forecast_length, min_allowed_train_percent, verbose)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mforecast_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     ):\n\u001b[0;32m--> 384\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    385\u001b[0m             \"\"\"forecast_length is too large for training data.\n\u001b[1;32m    386\u001b[0m \u001b[0mWhat\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0myou\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mhave\u001b[0m \u001b[0menough\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0mto\u001b[0m \u001b[0msupport\u001b[0m \u001b[0mcross\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0myour\u001b[0m \u001b[0mforecast_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: forecast_length is too large for training data.\nWhat this means is you don't have enough history to support cross validation with your forecast_length.\nVarious solutions include bringing in more data, alter min_allowed_train_percent to something smaller,\nand also setting a shorter forecast_length to class init for cross validation which you can then override with a longer value in .predict()\nThis error is also often caused by errors in inputing of or preshaping the data.\nCheck model.df_wide_numeric to make sure data was imported correctly.\n            "
          ]
        }
      ],
      "source": [
        "from autots import AutoTS\n",
        "model=AutoTS(forecast_length=4,frequency='infer',ensemble='simple')\n",
        "model=model.fit(data,date_col='period_end',value_col='followers_gained',id_col='None')\n",
        "prediction=model.predict()\n",
        "output =prediction.forecast\n",
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0quGTirTdca0CPYvSRdMW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}